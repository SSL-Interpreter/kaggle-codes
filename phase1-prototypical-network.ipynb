{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7253131,"sourceType":"datasetVersion","datasetId":4116518},{"sourceId":7414077,"sourceType":"datasetVersion","datasetId":4312397}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":249.865505,"end_time":"2024-01-01T10:01:38.636326","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-01T09:57:28.770821","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.448362,"end_time":"2024-01-01T09:57:32.631911","exception":false,"start_time":"2024-01-01T09:57:32.183549","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:22.002363Z","iopub.execute_input":"2024-01-20T10:17:22.002868Z","iopub.status.idle":"2024-01-20T10:17:22.020351Z","shell.execute_reply.started":"2024-01-20T10:17:22.002828Z","shell.execute_reply":"2024-01-20T10:17:22.018845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,silhouette_score \nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport csv\nimport ast\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.manifold import TSNE\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import LabelEncoder\nimport random\nfrom torch.optim import Adam\nfrom torch.nn.functional import cross_entropy\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"papermill":{"duration":5.383236,"end_time":"2024-01-01T09:57:38.023429","exception":false,"start_time":"2024-01-01T09:57:32.640193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:22.423840Z","iopub.execute_input":"2024-01-20T10:17:22.424362Z","iopub.status.idle":"2024-01-20T10:17:22.433445Z","shell.execute_reply.started":"2024-01-20T10:17:22.424318Z","shell.execute_reply":"2024-01-20T10:17:22.431894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# select n-way-k-shot data","metadata":{"papermill":{"duration":0.007548,"end_time":"2024-01-01T09:57:38.038963","exception":false,"start_time":"2024-01-01T09:57:38.031415","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Get 10 classses\n\n#Get all skeleton locations into a single cell\n\nimport csv\n\ndef SelectClasses(selected_classes):\n    # Specify the input and output file paths\n    input_path = '/kaggle/input/pre-trained-transformer/ssl-padded_matrix_file.csv'\n    output_path = '/kaggle/working/ssl-selected_classes.csv'\n    \n    # Open the input CSV file and the output CSV file\n    with open(input_path, 'r') as input_file, open(output_path, 'w', newline='') as output_file:\n\n        # Create a CSV reader object and a CSV writer object\n        reader = csv.reader(input_file)\n        writer = csv.writer(output_file)\n\n        # Iterate over each row in the input CSV file\n        for row in reader:\n\n            clss = row[-1]\n            \n            if (int(clss) in selected_classes):\n#                 print(\"clss\",clss)\n                row = row[:-1] + [clss]\n#                 print(row)\n                writer.writerow(row)\n","metadata":{"papermill":{"duration":0.019935,"end_time":"2024-01-01T09:57:38.066754","exception":false,"start_time":"2024-01-01T09:57:38.046819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:23.274041Z","iopub.execute_input":"2024-01-20T10:17:23.274562Z","iopub.status.idle":"2024-01-20T10:17:23.284894Z","shell.execute_reply.started":"2024-01-20T10:17:23.274522Z","shell.execute_reply":"2024-01-20T10:17:23.283155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\n\ndef extract_rows_by_label(rows_per_label):\n    # initialize a dictionary to hold the rows for each label\n    label_rows = {}\n    \n    input_file_path = \"/kaggle/working/ssl-selected_classes.csv\"\n    output_file_path_train = \"/kaggle/working/ssl-n-way-k-shot_train.csv\"\n    output_file_path_test = \"/kaggle/working/ssl-n-way-k-shot_test.csv\"\n\n\n    # open the input file and read its contents\n    with open(input_file_path, 'r') as file:\n        csv_reader = csv.reader(file)\n        for row in csv_reader:\n            # extract the label from the end of the row\n            label = row[-1]\n            \n            # add the row to the label's list in the dictionary\n            if label in label_rows:\n                label_rows[label].append(row)\n            else:\n                label_rows[label] = [row]\n\n    # loop through the labels and write the output rows to a single file\n    #train\n    with open(output_file_path_train, 'w', newline='') as file:\n        csv_writer = csv.writer(file)\n        for label, rows in label_rows.items():\n            # extract the first N rows for the label\n            rows_to_write = rows[:rows_per_label]\n            \n            # write each row to the output file with the label appended\n            for row in rows_to_write:\n                csv_writer.writerow(row)\n\n    #test\n    with open(output_file_path_test, 'w', newline='') as file:\n        csv_writer = csv.writer(file)\n        for label, rows in label_rows.items():\n            # extract the first N rows for the label\n            rows_to_write = rows[-rows_per_label:]\n\n            # write each row to the output file with the label appended\n            for row in rows_to_write:\n                csv_writer.writerow(row)","metadata":{"papermill":{"duration":0.022794,"end_time":"2024-01-01T09:57:38.097332","exception":false,"start_time":"2024-01-01T09:57:38.074538","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:23.940951Z","iopub.execute_input":"2024-01-20T10:17:23.942718Z","iopub.status.idle":"2024-01-20T10:17:23.958974Z","shell.execute_reply.started":"2024-01-20T10:17:23.942647Z","shell.execute_reply":"2024-01-20T10:17:23.957435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\n\ndef GenerateClasses(nb_of_classes, starting_number, ending_number):\n    selected_classes = random.sample(range(starting_number, ending_number), nb_of_classes)\n\n    # [0,1,3,4,5,30,31,33,34,35]\n    print(\"classes: \",selected_classes)\n    print(\"number of classes: \",len(selected_classes))\n    \n    return selected_classes\n","metadata":{"papermill":{"duration":0.017607,"end_time":"2024-01-01T09:57:38.122775","exception":false,"start_time":"2024-01-01T09:57:38.105168","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:24.385370Z","iopub.execute_input":"2024-01-20T10:17:24.386390Z","iopub.status.idle":"2024-01-20T10:17:24.393416Z","shell.execute_reply.started":"2024-01-20T10:17:24.386343Z","shell.execute_reply":"2024-01-20T10:17:24.391667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selected_classes = GenerateClasses(14,50,64)    # ( nb_of_classes, starting_number, ending_number )\n\n# selected_classes = [0,1,3,4,5,30,31,33,34,35]\n\nselected_classes = [i for i in range(25)]\n\nSelectClasses(selected_classes)\n\nextract_rows_by_label(10)   # k shot x 2\n","metadata":{"papermill":{"duration":19.439527,"end_time":"2024-01-01T09:57:57.570214","exception":false,"start_time":"2024-01-01T09:57:38.130687","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:24.832491Z","iopub.execute_input":"2024-01-20T10:17:24.832984Z","iopub.status.idle":"2024-01-20T10:17:35.181770Z","shell.execute_reply.started":"2024-01-20T10:17:24.832947Z","shell.execute_reply":"2024-01-20T10:17:35.180269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prototypical network","metadata":{"papermill":{"duration":0.007641,"end_time":"2024-01-01T09:57:57.585966","exception":false,"start_time":"2024-01-01T09:57:57.578325","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Your code for loading the data (unchanged)\ninput_file = \"/kaggle/working/ssl-n-way-k-shot_train.csv\"\n\nvalues = []\nmatrix_labels = []\nnum_rows = 0\n\nwith open(input_file, \"r\") as f_input:\n    reader = csv.reader(f_input)\n    for row in reader:\n        row_values = []\n        for i in range(len(row) - 1):\n            column_value = ast.literal_eval(row[i])\n            row_values.append(column_value)\n        values.append(torch.tensor(row_values))\n        matrix_labels.append(ast.literal_eval(row[-1]))\n        num_rows += 1\n        \nmatrix_labels = np.array(matrix_labels)","metadata":{"papermill":{"duration":38.175949,"end_time":"2024-01-01T09:58:35.769704","exception":false,"start_time":"2024-01-01T09:57:57.593755","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:35.184384Z","iopub.execute_input":"2024-01-20T10:17:35.184947Z","iopub.status.idle":"2024-01-20T10:17:55.946172Z","shell.execute_reply.started":"2024-01-20T10:17:35.184901Z","shell.execute_reply":"2024-01-20T10:17:55.944836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, n_features, d_model=32, nhead=32, num_layers=1):\n        super(TransformerEncoder, self).__init__()\n        self.embedding = nn.Linear(n_features, d_model)\n        self.positional_encoding = self.generate_positional_encoding(d_model)\n        self.transformer_encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model, nhead), num_layers\n        )\n\n    def generate_positional_encoding(self, d_model, max_len=257):\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)\n        )\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        return pe.unsqueeze(0)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x + self.positional_encoding[:, : x.size(1)]\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=1)\n        return x","metadata":{"papermill":{"duration":0.023973,"end_time":"2024-01-01T09:58:35.801839","exception":false,"start_time":"2024-01-01T09:58:35.777866","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:55.948128Z","iopub.execute_input":"2024-01-20T10:17:55.948649Z","iopub.status.idle":"2024-01-20T10:17:55.963478Z","shell.execute_reply.started":"2024-01-20T10:17:55.948600Z","shell.execute_reply":"2024-01-20T10:17:55.961851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PrototypicalNetworks(nn.Module):\n    def __init__(self, backbone: nn.Module):\n        super(PrototypicalNetworks, self).__init__()\n        self.backbone = backbone\n\n    def forward(\n        self,\n        support_images: torch.Tensor,\n        support_labels: torch.Tensor,\n        query_images: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"\n        Predict query labels using labeled support images.\n        \"\"\"\n        # Extract the features of support and query images\n        z_support = self.backbone.forward(support_images)\n        z_query = self.backbone.forward(query_images)\n\n        # Infer the number of different classes from the labels of the support set\n        n_way = len(torch.unique(support_labels))\n        # Prototype i is the mean of all instances of features corresponding to labels == i\n        z_proto = torch.cat(\n            [\n                z_support[torch.nonzero(support_labels == label)].mean(0)\n                for label in range(n_way)\n            ]\n        )\n#         print(z_proto.shape)\n#         print(z_query.shape, z_proto.shape)\n        # Compute the euclidean distance from queries to prototypes\n        dists = torch.cdist(z_query, z_proto)\n#         print(dists.shape)\n        scores = -dists\n        return scores\n    \n    def infer(self, input_data):\n        # Ensure the model is in evaluation mode\n        self.eval()\n\n        # Convert the input data to a PyTorch tensor\n        input_tensor = torch.tensor(input_data, dtype=torch.float32)\n\n        # Forward pass through the model\n        with torch.no_grad():\n            embeddings = self.backbone.forward(input_tensor)\n\n        return embeddings\n","metadata":{"papermill":{"duration":0.022056,"end_time":"2024-01-01T09:58:35.831739","exception":false,"start_time":"2024-01-01T09:58:35.809683","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:55.966922Z","iopub.execute_input":"2024-01-20T10:17:55.967593Z","iopub.status.idle":"2024-01-20T10:17:55.984133Z","shell.execute_reply.started":"2024-01-20T10:17:55.967543Z","shell.execute_reply":"2024-01-20T10:17:55.982674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data and split it into training and testing sets\n# train_values, test_values, train_matrix_labels, test_matrix_labels = train_test_split(values, matrix_labels, test_size=0.2, random_state=42, stratify=matrix_labels)\n\ntrain_values = torch.stack([torch.tensor(value) for value in values])\ntrain_matrix_labels = matrix_labels","metadata":{"papermill":{"duration":0.10608,"end_time":"2024-01-01T09:58:35.945959","exception":false,"start_time":"2024-01-01T09:58:35.839879","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:55.986033Z","iopub.execute_input":"2024-01-20T10:17:55.986594Z","iopub.status.idle":"2024-01-20T10:17:56.044487Z","shell.execute_reply.started":"2024-01-20T10:17:55.986539Z","shell.execute_reply":"2024-01-20T10:17:56.043157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved TransformerEncoder model\nsaved_model_path = \"/kaggle/input/pre-trained-transformer/pre-trained model with 64 classes-model_epoch_70.pt\"\n\ncheckpoint = torch.load(saved_model_path)\nunexpected_keys = [\"classification_head.weight\", \"classification_head.bias\"]\nfor key in unexpected_keys:\n    del checkpoint[key]\n\n# Instantiate the TransformerEncoder as the backbone\nn_features = 114\nencoder = TransformerEncoder(n_features=n_features)\nencoder.load_state_dict(checkpoint)","metadata":{"papermill":{"duration":0.122667,"end_time":"2024-01-01T09:58:36.076475","exception":false,"start_time":"2024-01-01T09:58:35.953808","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:56.049018Z","iopub.execute_input":"2024-01-20T10:17:56.049472Z","iopub.status.idle":"2024-01-20T10:17:56.072787Z","shell.execute_reply.started":"2024-01-20T10:17:56.049436Z","shell.execute_reply":"2024-01-20T10:17:56.071441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PrototypicalNetworks(encoder)","metadata":{"papermill":{"duration":0.017607,"end_time":"2024-01-01T09:58:36.102450","exception":false,"start_time":"2024-01-01T09:58:36.084843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:56.074632Z","iopub.execute_input":"2024-01-20T10:17:56.075629Z","iopub.status.idle":"2024-01-20T10:17:56.084246Z","shell.execute_reply.started":"2024-01-20T10:17:56.075567Z","shell.execute_reply":"2024-01-20T10:17:56.082587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_few_shot_task(embeddings, labels, n_way, k_shot, n_query):\n    unique_labels = np.unique(labels)\n    selected_labels = np.random.choice(unique_labels, n_way, replace=False)\n#     print(\"selected\",selected_labels)\n    # Create a dictionary for mapping the original labels to the new labels\n    label_map = {label: idx for idx, label in enumerate(selected_labels)}\n#     print(label_map)\n    support_set = []\n    query_set = []\n    support_labels = []\n    query_labels = []\n\n    for label in selected_labels:\n        class_embeddings = embeddings[labels == label]\n#         print(len(class_embeddings))\n        if len(class_embeddings) < k_shot + n_query:\n            continue\n        support_indices = np.random.choice(range(len(class_embeddings)), k_shot, replace=False)\n        query_indices = np.random.choice(np.delete(range(len(class_embeddings)), support_indices), n_query, replace=False)\n        \n        support_set.append(class_embeddings[support_indices].detach().numpy())\n        query_set.append(class_embeddings[query_indices].detach().numpy())\n        support_labels.extend([label_map[label]] * k_shot)\n        query_labels.extend([label_map[label]] * n_query)\n#     print(np.unique(support_labels))\n    support_set = np.concatenate(support_set, axis=0)\n    query_set = np.concatenate(query_set, axis=0)\n    support_labels = np.array(support_labels)\n    query_labels = np.array(query_labels)\n    \n    return support_set, query_set, support_labels, query_labels\n","metadata":{"papermill":{"duration":0.024472,"end_time":"2024-01-01T09:58:36.134917","exception":false,"start_time":"2024-01-01T09:58:36.110445","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:56.086066Z","iopub.execute_input":"2024-01-20T10:17:56.086493Z","iopub.status.idle":"2024-01-20T10:17:56.100385Z","shell.execute_reply.started":"2024-01-20T10:17:56.086451Z","shell.execute_reply":"2024-01-20T10:17:56.098952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training parameters\nn_epochs = 100\nn_way = 5\nk_shot = 5\nn_query = 5\nlr = 0.001\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\n# Training loop\nfor epoch in range(n_epochs):\n    print(f\"Epoch: {epoch + 1}/{n_epochs}\")\n#     print(np.unique(train_matrix_labels))\n    support_set, query_set, support_labels, query_labels = create_few_shot_task(train_values, np.array(train_matrix_labels), n_way, k_shot, n_query)\n    support_set = torch.tensor(support_set, dtype=torch.float32)\n    query_set = torch.tensor(query_set, dtype=torch.float32)\n    support_labels = torch.tensor(support_labels, dtype=torch.long)\n    model.train()\n    optimizer.zero_grad()\n    scores = model(support_set, support_labels, query_set)\n    loss = criterion(scores, torch.tensor(query_labels, dtype=torch.long))\n\n    loss.backward()\n    optimizer.step()\n#     print(scores)\n    # Compute accuracy\n    _, predictions = torch.max(scores, 1)\n#     print(predictions)\n#     print(query_labels)\n    accuracy = accuracy_score(query_labels, predictions.detach().numpy())\n    \n    # Calculate Silhouette Coefficient\n    with torch.no_grad():\n        query_embeddings = model.backbone.forward(query_set)\n    silhouette_coefficient = silhouette_score(query_embeddings.detach().numpy(), query_labels)\n\n#     print(f\"Loss: {loss.item()}, Accuracy: {accuracy * 100}%\")\n    print(f\"Loss: {loss.item()}, Accuracy: {accuracy * 100}%, Silhouette Coefficient: {silhouette_coefficient}\")","metadata":{"papermill":{"duration":102.516246,"end_time":"2024-01-01T10:00:18.659565","exception":false,"start_time":"2024-01-01T09:58:36.143319","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:17:56.102882Z","iopub.execute_input":"2024-01-20T10:17:56.103595Z","iopub.status.idle":"2024-01-20T10:19:55.999790Z","shell.execute_reply.started":"2024-01-20T10:17:56.103537Z","shell.execute_reply":"2024-01-20T10:19:55.997955Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testing","metadata":{"papermill":{"duration":0.017084,"end_time":"2024-01-01T10:00:18.694077","exception":false,"start_time":"2024-01-01T10:00:18.676993","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Your code for loading the data (unchanged)\ninput_file = \"/kaggle/working/ssl-n-way-k-shot_test.csv\"\n\nvalues = []\nmatrix_labels = []\nnum_rows = 0\n\nwith open(input_file, \"r\") as f_input:\n    reader = csv.reader(f_input)\n    for row in reader:\n        row_values = []\n        for i in range(len(row) - 1):\n            column_value = ast.literal_eval(row[i])\n            row_values.append(column_value)\n        values.append(torch.tensor(row_values))\n        matrix_labels.append(ast.literal_eval(row[-1]))\n        num_rows += 1\n        \nmatrix_labels = np.array(matrix_labels)","metadata":{"papermill":{"duration":38.153859,"end_time":"2024-01-01T10:00:56.865513","exception":false,"start_time":"2024-01-01T10:00:18.711654","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:19:56.004980Z","iopub.execute_input":"2024-01-20T10:19:56.006472Z","iopub.status.idle":"2024-01-20T10:20:17.101765Z","shell.execute_reply.started":"2024-01-20T10:19:56.006412Z","shell.execute_reply":"2024-01-20T10:20:17.100596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_values = torch.stack([torch.tensor(value) for value in values])\ntest_matrix_labels = matrix_labels","metadata":{"papermill":{"duration":0.069463,"end_time":"2024-01-01T10:00:56.952859","exception":false,"start_time":"2024-01-01T10:00:56.883396","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:20:17.103251Z","iopub.execute_input":"2024-01-20T10:20:17.103896Z","iopub.status.idle":"2024-01-20T10:20:17.132489Z","shell.execute_reply.started":"2024-01-20T10:20:17.103858Z","shell.execute_reply":"2024-01-20T10:20:17.131387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_few_shot_task_with_and_without_label_map(embeddings, labels, n_way, k_shot, n_query):\n    unique_labels = np.unique(labels)\n    selected_labels = np.random.choice(unique_labels, n_way, replace=False)\n#     print(\"selected\",selected_labels)\n    # Create a dictionary for mapping the original labels to the new labels\n    label_map = {label: idx for idx, label in enumerate(selected_labels)}\n    support_set = []\n    query_set = []\n    support_labels = []\n    unmapped_support_labels = []\n    query_labels = []\n    unmapped_query_labels = []\n\n    for label in selected_labels:\n        class_embeddings = embeddings[labels == label]\n#         print(len(class_embeddings))\n        if len(class_embeddings) < k_shot + n_query:\n            continue\n        support_indices = np.random.choice(range(len(class_embeddings)), k_shot, replace=False)\n        query_indices = np.random.choice(np.delete(range(len(class_embeddings)), support_indices), n_query, replace=False)\n        \n        support_set.append(class_embeddings[support_indices].detach().numpy())\n        query_set.append(class_embeddings[query_indices].detach().numpy())\n        support_labels.extend([label_map[label]] * k_shot)\n        unmapped_support_labels.extend([label] * k_shot)\n        query_labels.extend([label_map[label]] * n_query)\n        unmapped_query_labels.extend([label] * n_query)\n#         print(\"mapped\",np.unique(support_labels))\n#         print(\"unmapped\",np.unique(unmapped_support_labels))\n    support_set = np.concatenate(support_set, axis=0)\n    query_set = np.concatenate(query_set, axis=0)\n    support_labels = np.array(support_labels)\n    query_labels = np.array(query_labels)\n    \n    return support_set, query_set, support_labels, query_labels, unmapped_support_labels, unmapped_query_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T10:20:17.133802Z","iopub.execute_input":"2024-01-20T10:20:17.134793Z","iopub.status.idle":"2024-01-20T10:20:17.148095Z","shell.execute_reply.started":"2024-01-20T10:20:17.134753Z","shell.execute_reply":"2024-01-20T10:20:17.146766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(selected_classes)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T10:20:17.150131Z","iopub.execute_input":"2024-01-20T10:20:17.150567Z","iopub.status.idle":"2024-01-20T10:20:17.169577Z","shell.execute_reply.started":"2024-01-20T10:20:17.150530Z","shell.execute_reply":"2024-01-20T10:20:17.167770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prototypes = {}\ndef collect_prototypes(support_set,query_set, support_labels, n_way ):\n    support_embeddings = model.backbone(support_set)\n    z_proto = []\n\n    for label in selected_classes:\n        # Check if the label is in the support set\n        if label in support_labels:\n            # Calculate prototype for this label\n            proto = support_embeddings[torch.nonzero(support_labels == label)].mean(0)\n            z_proto.append(proto)\n\n            \n#     print(\"z_proto\",z_proto)\n    z_proto = torch.stack(z_proto)\n    prototype_embeddings = z_proto.detach().numpy()\n\n    unique_labels = np.unique(np.array(support_labels))\n    unique_labels, indices = np.unique(support_labels, return_index=True)\n\n    # Get the unique labels in their original order\n    unique_labels_in_original_order = unique_labels[np.argsort(indices)]\n    for i in range(len(unique_labels_in_original_order)):\n        \n        prototypes[support_labels[i].item()] =  list(prototype_embeddings[i])\n#         print(\"prototypes\",prototypes)\n#         print(\"-\" * 30)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T10:23:27.548033Z","iopub.execute_input":"2024-01-20T10:23:27.548650Z","iopub.status.idle":"2024-01-20T10:23:27.560329Z","shell.execute_reply.started":"2024-01-20T10:23:27.548607Z","shell.execute_reply":"2024-01-20T10:23:27.558789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the number of evaluation episodes\nn_evaluation_episodes = 100\n\n# Initialize the accuracy accumulator\ntotal_accuracy = 0\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Evaluation loop\nfor episode in range(n_evaluation_episodes):\n    support_set, query_set, support_labels, query_labels, unmapped_support_labels, unmapped_query_labels = create_few_shot_task_with_and_without_label_map(test_values, np.array(test_matrix_labels), n_way, k_shot, n_query)\n    support_set = torch.tensor(support_set, dtype=torch.float32)\n    query_set = torch.tensor(query_set, dtype=torch.float32)\n    support_labels = torch.tensor(support_labels, dtype=torch.long) \n    unmapped_support_labels = torch.tensor(unmapped_support_labels, dtype=torch.long) \n#     print(support_set, query_set,unmapped_support_labels, n_way )\n    collect_prototypes(support_set, query_set,unmapped_support_labels, n_way )\n    with torch.no_grad():\n        scores = model(support_set, support_labels, query_set)\n#         print(scores.shape)\n#         print(scores)\n        # Compute accuracy\n        _, predictions = torch.max(scores, 1)\n#         print(predictions.detach().numpy())\n#         print(query_labels)\n        accuracy = accuracy_score(query_labels, predictions.detach().numpy())\n#         print(accuracy)\n        # Calculate Silhouette Coefficient\n        with torch.no_grad():\n            query_embeddings = model.backbone.forward(query_set)\n            silhouette_coefficient = silhouette_score(query_embeddings.detach().numpy(), query_labels)\n        total_accuracy += accuracy\n        print(\"Accuracy: {:.2%}, Silhouette Coefficient: {:.2f}\".format(accuracy, silhouette_coefficient))\n\n# Compute the average accuracy over all evaluation episodes\naverage_accuracy = total_accuracy / n_evaluation_episodes\nprint(f\"Average accuracy: {average_accuracy * 100}%\")","metadata":{"papermill":{"duration":38.750749,"end_time":"2024-01-01T10:01:35.721044","exception":false,"start_time":"2024-01-01T10:00:56.970295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T10:23:28.126586Z","iopub.execute_input":"2024-01-20T10:23:28.127081Z","iopub.status.idle":"2024-01-20T10:24:09.990895Z","shell.execute_reply.started":"2024-01-20T10:23:28.127047Z","shell.execute_reply":"2024-01-20T10:24:09.989573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the dictionary into a list of tuples\ndata_tuples = [(list(v[0]), k) for k, v in prototypes.items()]\n\n# Convert the list of tuples into a DataFrame\ndf = pd.DataFrame(data_tuples, columns=['feature', 'label'])\n\n# Save to CSV\ndf.to_csv('/kaggle/working/prototypes_1.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-20T04:27:14.891896Z","iopub.execute_input":"2024-01-20T04:27:14.892379Z","iopub.status.idle":"2024-01-20T04:27:14.909123Z","shell.execute_reply.started":"2024-01-20T04:27:14.892336Z","shell.execute_reply":"2024-01-20T04:27:14.907533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_embeddings(embeddings, labels, markers, title):\n    # Apply t-SNE for dimensionality reduction to 2D\n    tsne = TSNE(n_components=2)\n    embeddings_tsne = tsne.fit_transform(embeddings)\n    \n    # Set up the figure for plotting\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Set up the color map (one color per class)\n    cmap = plt.cm.get_cmap('viridis', len(np.unique(labels)))\n\n    # Create an empty list to store legend handles\n    legend_handles = []\n\n    # Iterate through the unique labels to create a legend handle for each class\n    for label in np.unique(labels):\n        legend_handles.append(\n            plt.Line2D(\n                [0],\n                [0],\n                marker='o',\n                color=cmap(label),\n                label=f'Class {label}',\n                markerfacecolor=cmap(label),\n                markersize=8,\n                linestyle='None'\n            )\n        )\n\n    # Add the legend for the classes\n    ax.legend(handles=legend_handles, loc='upper left', title='Classes')\n\n    for idx, (embedding, label, marker) in enumerate(zip(embeddings_tsne, labels, markers)):\n        ax.scatter(*embedding, c=[cmap(label)], marker=marker, s=100)\n\n    # Add a legend for the marker types\n    support_marker = plt.Line2D([], [], color='k', marker='o', linestyle='None', markersize=10, label='Support Set')\n    query_marker = plt.Line2D([], [], color='k', marker='*', linestyle='None', markersize=10, label='Query Set')\n    prototype_marker = plt.Line2D([], [], color='k', marker='x', linestyle='None', markersize=10, label='Prototypes')\n\n    ax.legend(handles=[support_marker, query_marker, prototype_marker], loc='upper right', title='Marker Types')\n\n    # Configure plot appearance\n    ax.set_title(title)\n    ax.set_xlabel(\"t-SNE 1\")\n    ax.set_ylabel(\"t-SNE 2\")\n    plt.show()\n\n","metadata":{"papermill":{"duration":1.675141,"end_time":"2024-01-01T10:01:37.423721","exception":false,"start_time":"2024-01-01T10:01:35.748580","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T04:27:14.911193Z","iopub.execute_input":"2024-01-20T04:27:14.911870Z","iopub.status.idle":"2024-01-20T04:27:14.930412Z","shell.execute_reply.started":"2024-01-20T04:27:14.911835Z","shell.execute_reply":"2024-01-20T04:27:14.928815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"support_set, query_set, support_labels, query_labels = create_few_shot_task(test_values, np.array(test_matrix_labels), n_way, k_shot, 5)\nsupport_set = torch.tensor(support_set, dtype=torch.float32)\nquery_set = torch.tensor(query_set, dtype=torch.float32)\nsupport_labels = torch.tensor(support_labels, dtype=torch.long) \n\n\n# Extract embeddings and labels for support set, query set, and prototypes\nsupport_embeddings = model.backbone(support_set)\n\nz_proto = torch.cat(\n            [\n                support_embeddings[torch.nonzero(support_labels == label)].mean(0)\n                for label in range(n_way)\n            ]\n        )\n\nsupport_embeddings = support_embeddings.detach().numpy()\nquery_embeddings = model.backbone(query_set).detach().numpy()\nprototype_embeddings = z_proto.detach().numpy()\n\n# Create markers for support set ('o'), query set ('*'), and prototypes ('x')\nsupport_markers = ['o'] * len(support_labels)\nquery_markers = ['*'] * len(query_labels)\nprototype_markers = ['x'] * len(np.unique(support_labels))\n\n# Concatenate support, query, and prototype data\nall_embeddings = np.concatenate([support_embeddings, query_embeddings, prototype_embeddings], axis=0)\nall_labels = np.concatenate([support_labels, query_labels, np.unique(support_labels)], axis=0)\nall_markers = support_markers + query_markers + prototype_markers\n\n# Visualize the embeddings\nvisualize_embeddings(all_embeddings, all_labels, all_markers, \"Support, Query, and Prototype Embeddings\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T04:27:14.932300Z","iopub.execute_input":"2024-01-20T04:27:14.932728Z","iopub.status.idle":"2024-01-20T04:27:16.217449Z","shell.execute_reply.started":"2024-01-20T04:27:14.932671Z","shell.execute_reply":"2024-01-20T04:27:16.216364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\ntorch.save(model.state_dict(), \"/kaggle/working/prototypicalNetwork_1.pt\")","metadata":{"papermill":{"duration":0.027869,"end_time":"2024-01-01T10:01:37.483227","exception":false,"start_time":"2024-01-01T10:01:37.455358","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T04:27:16.218627Z","iopub.execute_input":"2024-01-20T04:27:16.219577Z","iopub.status.idle":"2024-01-20T04:27:16.228693Z","shell.execute_reply.started":"2024-01-20T04:27:16.219537Z","shell.execute_reply":"2024-01-20T04:27:16.227241Z"},"trusted":true},"execution_count":null,"outputs":[]}]}