{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7572877,"sourceType":"datasetVersion","datasetId":4408301},{"sourceId":7589191,"sourceType":"datasetVersion","datasetId":4313301},{"sourceId":7598100,"sourceType":"datasetVersion","datasetId":4422867},{"sourceId":162265006,"sourceType":"kernelVersion"},{"sourceId":162301601,"sourceType":"kernelVersion"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":14909.183508,"end_time":"2024-02-09T10:39:10.998638","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-09T06:30:41.815130","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# SGD -> Adam\n# dropout -> 0.2\n# dropout to Z\n# pretraining lr -> 0.001\n# weight decay -> 0.001\n# epoch 1000 to pretrain\n# batch wise pretraining\n# gpu enabled","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":6.895244,"end_time":"2024-02-09T06:30:53.479687","exception":false,"start_time":"2024-02-09T06:30:46.584443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T07:04:27.214252Z","iopub.execute_input":"2024-02-10T07:04:27.214542Z","iopub.status.idle":"2024-02-10T07:04:27.219358Z","shell.execute_reply.started":"2024-02-10T07:04:27.214518Z","shell.execute_reply":"2024-02-10T07:04:27.218416Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport ast\nimport torch.optim as optim\nimport csv\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import TensorDataset\n\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:26:37.055688Z","iopub.execute_input":"2024-02-10T09:26:37.056379Z","iopub.status.idle":"2024-02-10T09:26:41.629852Z","shell.execute_reply.started":"2024-02-10T09:26:37.056342Z","shell.execute_reply":"2024-02-10T09:26:41.628864Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:26:41.631608Z","iopub.execute_input":"2024-02-10T09:26:41.632004Z","iopub.status.idle":"2024-02-10T09:26:41.687881Z","shell.execute_reply.started":"2024-02-10T09:26:41.631978Z","shell.execute_reply":"2024-02-10T09:26:41.686823Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Read the prototypes CSV file\ndf = pd.read_csv('/kaggle/input/transformer-instances-with-prototypes/zero_to_fifty/prototypes_3.csv')\ndf1 = pd.read_csv('/kaggle/input/transformer-instances-with-prototypes/gsl_zero_to_fifty_three/prototypes_3.csv')\n\n# Convert to a dictionary\nssl_prototypes = pd.Series(df['feature'].values,index=df['label']).to_dict()\ngsl_prototypes = pd.Series(df1['feature'].values,index=df1['label']).to_dict()\n\n\n# Read train data CSV file\n# df_train = pd.read_csv('/kaggle/input/transformer-instances-with-prototypes/zero_to_fifty/ssl-n-way-k-shot_train_3.csv')\n\n# Evaluate string representations of Python literals\nssl_prototypes = {k: ast.literal_eval(v) for k, v in ssl_prototypes.items()}\ngsl_prototypes = {k: ast.literal_eval(v) for k, v in gsl_prototypes.items()}","metadata":{"papermill":{"duration":0.105267,"end_time":"2024-02-09T06:30:53.591312","exception":false,"start_time":"2024-02-09T06:30:53.486045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:26:41.689165Z","iopub.execute_input":"2024-02-10T09:26:41.689457Z","iopub.status.idle":"2024-02-10T09:26:41.775560Z","shell.execute_reply.started":"2024-02-10T09:26:41.689432Z","shell.execute_reply":"2024-02-10T09:26:41.774823Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class STFE(nn.Module): # Salient Temporal Feature Extractor\n    def __init__(self, d, d_prime, d_double_prime):\n        super(STFE, self).__init__()\n        # Initialize learnable parameters with appropriate layers\n        self.W_X = nn.Linear(d_prime, d)\n        self.W_M = nn.Linear(d_prime, d)\n        self.W_delta = nn.Linear(d_prime, d)\n        self.W_u = nn.Linear(d, d_prime)\n        self.W_P = nn.Linear(d_double_prime, d)\n        self.W_Q = nn.Linear(d_double_prime, d)\n        self.W_V = nn.Linear(d_double_prime, d)\n        self.W_O = nn.Linear(d, d_double_prime)\n        self.fc = nn.Linear(d, 54)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, X, M):\n        # Define forward function\n        r = torch.softmax(X @ self.W_X.weight @ (M @ self.W_M.weight).t(), dim=1)\n        U = r @ (M @ (self.W_M.weight + self.W_delta.weight))\n        Z = U @ self.W_u.weight + X\n        Z = self.dropout(Z)  # Apply dropout after the activation function\n        P = torch.max(Z, dim=0)[0]\n        S = P @ self.W_P.weight @ (X @ self.W_Q.weight).t()\n        A = torch.softmax(S, dim=0)\n        V = self.fc(A @ (X @ self.W_V.weight @ self.W_O.weight))\n        return V","metadata":{"papermill":{"duration":0.021057,"end_time":"2024-02-09T06:30:53.618222","exception":false,"start_time":"2024-02-09T06:30:53.597165","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:26:41.777218Z","iopub.execute_input":"2024-02-10T09:26:41.777495Z","iopub.status.idle":"2024-02-10T09:26:41.787175Z","shell.execute_reply.started":"2024-02-10T09:26:41.777472Z","shell.execute_reply":"2024-02-10T09:26:41.786327Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define the dataset class\nclass SkeletonDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:26:41.788281Z","iopub.execute_input":"2024-02-10T09:26:41.788620Z","iopub.status.idle":"2024-02-10T09:26:41.800237Z","shell.execute_reply.started":"2024-02-10T09:26:41.788590Z","shell.execute_reply":"2024-02-10T09:26:41.799441Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ssl_sorted_prototypes = dict(sorted(ssl_prototypes.items()))\nssl_sorted_prototype_values = torch.tensor(list(ssl_sorted_prototypes.values()))\nssl_sorted_prototype_values = ssl_sorted_prototype_values.to(device)\n\ngsl_sorted_prototypes = dict(sorted(gsl_prototypes.items()))\ngsl_sorted_prototype_values = torch.tensor(list(gsl_sorted_prototypes.values()))\ngsl_sorted_prototype_values = gsl_sorted_prototype_values.to(device)","metadata":{"papermill":{"duration":0.040589,"end_time":"2024-02-09T06:30:53.687036","exception":false,"start_time":"2024-02-09T06:30:53.646447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:26:41.801305Z","iopub.execute_input":"2024-02-10T09:26:41.801575Z","iopub.status.idle":"2024-02-10T09:26:42.026852Z","shell.execute_reply.started":"2024-02-10T09:26:41.801553Z","shell.execute_reply":"2024-02-10T09:26:42.026064Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Training","metadata":{"papermill":{"duration":0.005463,"end_time":"2024-02-09T06:30:53.698378","exception":false,"start_time":"2024-02-09T06:30:53.692915","status":"completed"},"tags":[]}},{"cell_type":"code","source":"values = []\nmatrix_labels = []\ninput_file = '/kaggle/input/gsl-matrix-file/gsl-padded_matrix_file.csv'\nwith open(input_file, \"r\") as f_input:\n    reader = csv.reader(f_input)\n    for row in reader:\n        row_values = []\n        for i in range(len(row) - 1):\n            column_value = ast.literal_eval(row[i])\n            row_values.append(column_value)\n        values.append(torch.tensor(row_values))\n        matrix_labels.append(ast.literal_eval(row[-1]))\n        \nmatrix_labels = np.array(matrix_labels)\n\ntrain_values = torch.stack([value.clone().detach() for value in values])\ntrain_matrix_labels = matrix_labels","metadata":{"papermill":{"duration":130.36362,"end_time":"2024-02-09T06:33:04.067788","exception":false,"start_time":"2024-02-09T06:30:53.704168","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:26:46.251801Z","iopub.execute_input":"2024-02-10T09:26:46.252166Z","iopub.status.idle":"2024-02-10T09:28:48.903962Z","shell.execute_reply.started":"2024-02-10T09:26:46.252135Z","shell.execute_reply":"2024-02-10T09:28:48.903150Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# map classes to 0 to 49\nadjusted_train_matrix_labels = train_matrix_labels.copy()\nadjusted_train_values = train_values.clone()  # Use clone for PyTorch tensors\nun_labels = np.unique(train_matrix_labels)\n\nfor i in range(len(un_labels)):\n#     if i >= 50:\n#         # indexes of adjusted_train_matrix_labels which has un_labels[i] should be removed from both adjusted_train_matrix_labels and adjusted_train_values\n#         indices_to_remove = np.where(adjusted_train_matrix_labels == un_labels[i])[0].tolist()\n#         adjusted_train_matrix_labels = np.delete(adjusted_train_matrix_labels, indices_to_remove)\n#         adjusted_train_values = torch.stack([adjusted_train_values[i] for i in range(len(adjusted_train_values)) if i not in indices_to_remove])  # Use torch.stack for multi-dimensional tensors\n#     else:\n        adjusted_train_matrix_labels[adjusted_train_matrix_labels == un_labels[i]] = i","metadata":{"papermill":{"duration":0.203927,"end_time":"2024-02-09T06:33:04.277821","exception":false,"start_time":"2024-02-09T06:33:04.073894","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:28:48.905760Z","iopub.execute_input":"2024-02-10T09:28:48.906111Z","iopub.status.idle":"2024-02-10T09:28:48.997301Z","shell.execute_reply.started":"2024-02-10T09:28:48.906080Z","shell.execute_reply":"2024-02-10T09:28:48.996297Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"d = adjusted_train_values[0].shape[1]\nd_prime = adjusted_train_values[0].shape[0]\nd_doble_prime = adjusted_train_values[0].shape[0]\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n    adjusted_train_values, torch.tensor(adjusted_train_matrix_labels), test_size=0.4, random_state=42, stratify=torch.tensor(adjusted_train_matrix_labels)\n)\n\n# validation_data, test_data, validation_labels, test_labels = train_test_split(\n#     test_data, test_labels, test_size=0.5, random_state=42, stratify=test_labels\n# )","metadata":{"papermill":{"duration":0.198597,"end_time":"2024-02-09T06:33:04.482786","exception":false,"start_time":"2024-02-09T06:33:04.284189","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:28:48.998539Z","iopub.execute_input":"2024-02-10T09:28:48.998875Z","iopub.status.idle":"2024-02-10T09:28:49.108955Z","shell.execute_reply.started":"2024-02-10T09:28:48.998845Z","shell.execute_reply":"2024-02-10T09:28:49.107836Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create train, validation, and test datasets\ntrain_dataset = SkeletonDataset(train_data, train_labels)\ntest_dataset = SkeletonDataset(test_data, test_labels)\n\npre_train_batch_size = 32\n\n# Create data loaders for train, validation, and test sets\ntrain_loader = DataLoader(train_dataset, batch_size=pre_train_batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=pre_train_batch_size, shuffle=False)\n\n# Initialize the network\n\nstfe = STFE(d, d_prime, d_doble_prime)\nstfe.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(stfe.parameters(), lr=0.001, weight_decay=0.001)\n\ntrain_losses = []\nvalidation_losses = []\n\nnum_epochs = 1000\n\nfor epoch in range(num_epochs):  # loop over the dataset multiple times\n    stfe.train()\n    epoch_train_loss = 0\n    for batch_idx, (data, labels) in enumerate(train_loader):\n        data, labels = data.to(device), labels.to(device)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward + backward + optimize\n        for i in range(len(data)):  # loop over each element in data\n            output = stfe(data[i], gsl_sorted_prototype_values)\n            loss = criterion(output, labels[i])\n            loss.backward()            \n            epoch_train_loss += loss.item()\n            \n        optimizer.step()\n        \n    epoch_train_loss /= len(train_loader.dataset)\n    \n    train_losses.append(epoch_train_loss)\n    \n    # Calculate validation loss\n    stfe.eval()\n    epoch_validation_loss = 0\n    with torch.no_grad():\n        for batch_idx, (data, labels) in enumerate(test_loader):\n            data, labels = data.to(device), labels.to(device)\n            for i in range(len(data)):\n                outputs = stfe(data[i], gsl_sorted_prototype_values)\n                loss = criterion(outputs, labels[i])\n                epoch_validation_loss += loss.item()\n    epoch_validation_loss /= len(test_loader.dataset)\n    validation_losses.append(epoch_validation_loss)  \n    \n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_validation_loss:.4f}\")\n\n    # Save the model\n    torch.save(stfe.state_dict(), f\"/kaggle/working/model_epoch_{epoch + 1}.pt\")\n\n# Plot training and validation losses\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(validation_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":14449.235173,"end_time":"2024-02-09T10:33:53.724107","exception":false,"start_time":"2024-02-09T06:33:04.488934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-09T18:21:09.151509Z","iopub.execute_input":"2024-02-09T18:21:09.151972Z","iopub.status.idle":"2024-02-09T18:21:31.072430Z","shell.execute_reply.started":"2024-02-09T18:21:09.151931Z","shell.execute_reply":"2024-02-09T18:21:31.070960Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/1000, Train Loss: 3.9821, Validation Loss: 3.9738\nEpoch 2/1000, Train Loss: 3.9677, Validation Loss: 3.9453\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     output \u001b[38;5;241m=\u001b[39m net(data[i], gsl_sorted_prototype_values)\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, labels[i])\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m     38\u001b[0m     epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"torch.save(stfe.state_dict(), '/kaggle/working/pretrained_stfe.pt')","metadata":{"papermill":{"duration":0.083942,"end_time":"2024-02-09T10:33:54.031737","exception":false,"start_time":"2024-02-09T10:33:53.947795","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-09T17:25:01.093242Z","iopub.status.idle":"2024-02-09T17:25:01.093656Z","shell.execute_reply.started":"2024-02-09T17:25:01.093473Z","shell.execute_reply":"2024-02-09T17:25:01.093490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training & Evaluation","metadata":{"papermill":{"duration":0.071115,"end_time":"2024-02-09T10:33:54.173781","exception":false,"start_time":"2024-02-09T10:33:54.102666","status":"completed"},"tags":[]}},{"cell_type":"code","source":"values = []\nmatrix_labels = []\ninput_file = '/kaggle/input/transformer-instances-with-prototypes/zero_to_fifty/ssl-n-way-k-shot_train.csv'\nwith open(input_file, \"r\") as f_input:\n    reader = csv.reader(f_input)\n    for row in reader:\n        row_values = []\n        for i in range(len(row) - 1):\n            column_value = ast.literal_eval(row[i])\n            row_values.append(column_value)\n        values.append(torch.tensor(row_values))\n        matrix_labels.append(ast.literal_eval(row[-1]))\n        \nmatrix_labels = np.array(matrix_labels)\n\ntrain_values = torch.stack([value.clone().detach() for value in values])\ntrain_matrix_labels = matrix_labels","metadata":{"papermill":{"duration":35.397374,"end_time":"2024-02-09T10:34:29.642924","exception":false,"start_time":"2024-02-09T10:33:54.245550","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:28:49.111173Z","iopub.execute_input":"2024-02-10T09:28:49.111472Z","iopub.status.idle":"2024-02-10T09:29:22.132977Z","shell.execute_reply.started":"2024-02-10T09:28:49.111447Z","shell.execute_reply":"2024-02-10T09:29:22.132151Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Your code for loading the data (unchanged)\ninput_file = \"/kaggle/input/transformer-instances-with-prototypes/zero_to_fifty/ssl-n-way-k-shot_test.csv\"\n\nvalues = []\nmatrix_labels = []\n\nwith open(input_file, \"r\") as f_input:\n    reader = csv.reader(f_input)\n    for row in reader:\n        row_values = []\n        for i in range(len(row) - 1):\n            column_value = ast.literal_eval(row[i])\n            row_values.append(column_value)\n        values.append(torch.tensor(row_values))\n        matrix_labels.append(ast.literal_eval(row[-1]))\n        \nmatrix_labels = np.array(matrix_labels)\ntest_values = torch.stack([value.clone().detach() for value in values])\ntest_matrix_labels = matrix_labels","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:29:22.134110Z","iopub.execute_input":"2024-02-10T09:29:22.134382Z","iopub.status.idle":"2024-02-10T09:29:54.968102Z","shell.execute_reply.started":"2024-02-10T09:29:22.134359Z","shell.execute_reply":"2024-02-10T09:29:54.967301Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Concatenate along the first dimension (0)\nall_values = torch.cat((train_values, test_values), 0)\nall_labels = np.concatenate((train_matrix_labels, test_matrix_labels), axis=0)\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n    all_values, torch.tensor(all_labels), test_size=0.2, random_state=42, stratify=torch.tensor(all_labels)\n)\nvalidation_data, test_data, validation_labels, test_labels = train_test_split(\n    test_data, test_labels, test_size=0.7, random_state=42, stratify=test_labels\n)\n\n# Create train, validation, and test datasets\ntrain_dataset = SkeletonDataset(train_data, train_labels)\nvalidation_dataset = SkeletonDataset(validation_data, validation_labels)\ntest_dataset = SkeletonDataset(test_data, test_labels)\n\ntrain_batch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=train_batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=train_batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:30:39.748755Z","iopub.execute_input":"2024-02-10T09:30:39.749523Z","iopub.status.idle":"2024-02-10T09:30:39.874276Z","shell.execute_reply.started":"2024-02-10T09:30:39.749481Z","shell.execute_reply":"2024-02-10T09:30:39.872996Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T07:02:58.746231Z","iopub.execute_input":"2024-02-10T07:02:58.747764Z","iopub.status.idle":"2024-02-10T07:02:58.756883Z","shell.execute_reply.started":"2024-02-10T07:02:58.747697Z","shell.execute_reply":"2024-02-10T07:02:58.755581Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"600"},"metadata":{}}]},{"cell_type":"code","source":"# Convert labels to tensor if they are numpy arrays\nif isinstance(train_matrix_labels, np.ndarray):\n    train_matrix_labels = torch.from_numpy(train_matrix_labels)\n    \n# Initialize the network\nstfe = STFE(d, d_prime, d_doble_prime)\nstfe.load_state_dict(torch.load('/kaggle/input/best-model/model_epoch_998.pt'))\n\n# # Freeze all layers\n# for param in stfe.parameters():\n#     param.requires_grad = False\n\n# Replace the last layer\nstfe.fc = nn.Linear(d, 50)\nstfe.to(device)\n# # Unfreeze the last layer\n# for param in stfe.fc.parameters():\n#     param.requires_grad = True\n\n# Define a loss function and an optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(stfe.parameters(), lr=0.001, weight_decay=0.001)\n\ntrain_losses = []\nvalidation_losses = []\n\nnum_epochs = 100\n# Training loop\nfor epoch in range(num_epochs):  # loop over the dataset multiple times\n    stfe.train()\n    epoch_train_loss = 0\n    for batch_idx, (data, labels) in enumerate(train_loader):\n        data, labels = data.to(device), labels.to(device)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        for i in range(len(data)):\n        # forward + backward + optimize\n            outputs = stfe(data[i], ssl_sorted_prototype_values)\n            loss = criterion(outputs, labels[i])\n            loss.backward()\n            epoch_train_loss += loss.item()\n        optimizer.step()\n        \n    epoch_train_loss /= len(train_loader.dataset)\n    \n    train_losses.append(epoch_train_loss)\n\n    # Calculate validation loss\n    stfe.eval()\n    epoch_validation_loss = 0\n    with torch.no_grad():\n        for batch_idx, (data, labels) in enumerate(validation_loader):\n            data, labels = data.to(device), labels.to(device)\n            for i in range(len(data)):\n                outputs = stfe(data[i], ssl_sorted_prototype_values)\n                loss = criterion(outputs, labels[i])\n                epoch_validation_loss += loss.item()\n    epoch_validation_loss /= len(validation_loader.dataset)\n    validation_losses.append(epoch_validation_loss)  \n    \n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_validation_loss:.4f}\")\n    \n    # Save the model\n    torch.save(stfe.state_dict(), f\"/kaggle/working/model_epoch_{epoch + 1}.pt\")\n        \n# Plot training and validation losses\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(validation_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","metadata":{"papermill":{"duration":242.927634,"end_time":"2024-02-09T10:38:32.641872","exception":false,"start_time":"2024-02-09T10:34:29.714238","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:30:42.704274Z","iopub.execute_input":"2024-02-10T09:30:42.704668Z","iopub.status.idle":"2024-02-10T09:55:32.947328Z","shell.execute_reply.started":"2024-02-10T09:30:42.704636Z","shell.execute_reply":"2024-02-10T09:55:32.946392Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/1000, Train Loss: 3.7164, Validation Loss: 3.2407\nEpoch 2/1000, Train Loss: 2.7337, Validation Loss: 2.3342\nEpoch 3/1000, Train Loss: 2.1484, Validation Loss: 2.1188\nEpoch 4/1000, Train Loss: 1.8867, Validation Loss: 1.9657\nEpoch 5/1000, Train Loss: 1.6879, Validation Loss: 1.8887\nEpoch 6/1000, Train Loss: 1.5966, Validation Loss: 1.7714\nEpoch 7/1000, Train Loss: 1.4819, Validation Loss: 1.7204\nEpoch 8/1000, Train Loss: 1.3772, Validation Loss: 1.6636\nEpoch 9/1000, Train Loss: 1.2753, Validation Loss: 1.5970\nEpoch 10/1000, Train Loss: 1.1962, Validation Loss: 1.5385\nEpoch 11/1000, Train Loss: 1.1738, Validation Loss: 1.5247\nEpoch 12/1000, Train Loss: 1.1668, Validation Loss: 1.5345\nEpoch 13/1000, Train Loss: 1.1057, Validation Loss: 1.4335\nEpoch 14/1000, Train Loss: 0.9945, Validation Loss: 1.4766\nEpoch 15/1000, Train Loss: 0.9939, Validation Loss: 1.5138\nEpoch 16/1000, Train Loss: 0.9678, Validation Loss: 1.3294\nEpoch 17/1000, Train Loss: 0.9587, Validation Loss: 1.6142\nEpoch 18/1000, Train Loss: 0.8814, Validation Loss: 1.2891\nEpoch 19/1000, Train Loss: 0.8282, Validation Loss: 1.1115\nEpoch 20/1000, Train Loss: 0.8306, Validation Loss: 1.2310\nEpoch 21/1000, Train Loss: 0.7975, Validation Loss: 1.2435\nEpoch 22/1000, Train Loss: 0.7808, Validation Loss: 1.3761\nEpoch 23/1000, Train Loss: 0.7763, Validation Loss: 1.3182\nEpoch 24/1000, Train Loss: 0.8196, Validation Loss: 1.2756\nEpoch 25/1000, Train Loss: 0.7525, Validation Loss: 1.1619\nEpoch 26/1000, Train Loss: 0.7171, Validation Loss: 1.0201\nEpoch 27/1000, Train Loss: 0.7098, Validation Loss: 1.0954\nEpoch 28/1000, Train Loss: 0.6783, Validation Loss: 1.1088\nEpoch 29/1000, Train Loss: 0.6739, Validation Loss: 1.1127\nEpoch 30/1000, Train Loss: 0.7019, Validation Loss: 1.1273\nEpoch 31/1000, Train Loss: 0.7205, Validation Loss: 1.3964\nEpoch 32/1000, Train Loss: 0.6785, Validation Loss: 1.1184\nEpoch 33/1000, Train Loss: 0.6655, Validation Loss: 1.6044\nEpoch 34/1000, Train Loss: 0.6320, Validation Loss: 1.4099\nEpoch 35/1000, Train Loss: 0.7667, Validation Loss: 1.1381\nEpoch 36/1000, Train Loss: 0.6709, Validation Loss: 1.2591\nEpoch 37/1000, Train Loss: 0.6803, Validation Loss: 0.8481\nEpoch 38/1000, Train Loss: 0.6966, Validation Loss: 1.2055\nEpoch 39/1000, Train Loss: 0.6388, Validation Loss: 1.1928\nEpoch 40/1000, Train Loss: 0.6234, Validation Loss: 1.0850\nEpoch 41/1000, Train Loss: 0.5597, Validation Loss: 1.7822\nEpoch 42/1000, Train Loss: 0.5850, Validation Loss: 1.4766\nEpoch 43/1000, Train Loss: 0.5414, Validation Loss: 1.2115\nEpoch 44/1000, Train Loss: 0.5240, Validation Loss: 1.1180\nEpoch 45/1000, Train Loss: 0.5150, Validation Loss: 1.4269\nEpoch 46/1000, Train Loss: 0.5663, Validation Loss: 0.8989\nEpoch 47/1000, Train Loss: 0.4735, Validation Loss: 0.9968\nEpoch 48/1000, Train Loss: 0.5113, Validation Loss: 1.4367\nEpoch 49/1000, Train Loss: 0.5480, Validation Loss: 1.4085\nEpoch 50/1000, Train Loss: 0.4874, Validation Loss: 1.7817\nEpoch 51/1000, Train Loss: 0.5452, Validation Loss: 1.3990\nEpoch 52/1000, Train Loss: 0.4964, Validation Loss: 1.2286\nEpoch 53/1000, Train Loss: 0.4487, Validation Loss: 0.7979\nEpoch 54/1000, Train Loss: 0.4528, Validation Loss: 1.1743\nEpoch 55/1000, Train Loss: 0.5325, Validation Loss: 1.3217\nEpoch 56/1000, Train Loss: 0.5625, Validation Loss: 1.9662\nEpoch 57/1000, Train Loss: 0.5092, Validation Loss: 1.5987\nEpoch 58/1000, Train Loss: 0.4325, Validation Loss: 1.4645\nEpoch 59/1000, Train Loss: 0.4393, Validation Loss: 1.1913\nEpoch 60/1000, Train Loss: 0.4426, Validation Loss: 1.4245\nEpoch 61/1000, Train Loss: 0.4252, Validation Loss: 1.0742\nEpoch 62/1000, Train Loss: 0.4420, Validation Loss: 0.9093\nEpoch 63/1000, Train Loss: 0.3969, Validation Loss: 1.1296\nEpoch 64/1000, Train Loss: 0.4067, Validation Loss: 1.1974\nEpoch 65/1000, Train Loss: 0.3925, Validation Loss: 0.9796\nEpoch 66/1000, Train Loss: 0.4332, Validation Loss: 0.9803\nEpoch 67/1000, Train Loss: 0.4985, Validation Loss: 1.0756\nEpoch 68/1000, Train Loss: 0.4830, Validation Loss: 0.8766\nEpoch 69/1000, Train Loss: 0.3953, Validation Loss: 1.0204\nEpoch 70/1000, Train Loss: 0.3623, Validation Loss: 0.8822\nEpoch 71/1000, Train Loss: 0.3914, Validation Loss: 0.9667\nEpoch 72/1000, Train Loss: 0.3866, Validation Loss: 0.9278\nEpoch 73/1000, Train Loss: 0.3430, Validation Loss: 0.9322\nEpoch 74/1000, Train Loss: 0.3795, Validation Loss: 1.8135\nEpoch 75/1000, Train Loss: 0.4125, Validation Loss: 1.0416\nEpoch 76/1000, Train Loss: 0.3628, Validation Loss: 0.9020\nEpoch 77/1000, Train Loss: 0.3332, Validation Loss: 0.9102\nEpoch 78/1000, Train Loss: 0.3354, Validation Loss: 1.0544\nEpoch 79/1000, Train Loss: 0.3531, Validation Loss: 1.1444\nEpoch 80/1000, Train Loss: 0.3607, Validation Loss: 1.0589\nEpoch 81/1000, Train Loss: 0.3649, Validation Loss: 1.2294\nEpoch 82/1000, Train Loss: 0.3372, Validation Loss: 0.9330\nEpoch 83/1000, Train Loss: 0.3455, Validation Loss: 1.3503\nEpoch 84/1000, Train Loss: 0.3797, Validation Loss: 0.8257\nEpoch 85/1000, Train Loss: 0.3187, Validation Loss: 0.9572\nEpoch 86/1000, Train Loss: 0.3361, Validation Loss: 0.9206\nEpoch 87/1000, Train Loss: 0.3484, Validation Loss: 1.5557\nEpoch 88/1000, Train Loss: 0.3780, Validation Loss: 1.3407\nEpoch 89/1000, Train Loss: 0.4180, Validation Loss: 1.8755\nEpoch 90/1000, Train Loss: 0.4468, Validation Loss: 1.6195\nEpoch 91/1000, Train Loss: 0.4976, Validation Loss: 2.8986\nEpoch 92/1000, Train Loss: 0.4083, Validation Loss: 1.2470\nEpoch 93/1000, Train Loss: 0.4432, Validation Loss: 0.9440\nEpoch 94/1000, Train Loss: 0.6075, Validation Loss: 4.3325\nEpoch 95/1000, Train Loss: 0.4221, Validation Loss: 7.5743\nEpoch 96/1000, Train Loss: 0.3744, Validation Loss: 7.8937\nEpoch 97/1000, Train Loss: 0.3854, Validation Loss: 2.9414\nEpoch 98/1000, Train Loss: 0.3652, Validation Loss: 2.8620\nEpoch 99/1000, Train Loss: 0.3909, Validation Loss: 3.7159\nEpoch 100/1000, Train Loss: 0.3016, Validation Loss: 3.1797\nEpoch 101/1000, Train Loss: 0.3251, Validation Loss: 2.8941\nEpoch 102/1000, Train Loss: 0.3741, Validation Loss: 3.0952\nEpoch 103/1000, Train Loss: 0.2485, Validation Loss: 2.9322\nEpoch 104/1000, Train Loss: 0.2669, Validation Loss: 2.4588\nEpoch 105/1000, Train Loss: 0.2534, Validation Loss: 2.5476\nEpoch 106/1000, Train Loss: 0.2917, Validation Loss: 3.0799\nEpoch 107/1000, Train Loss: 0.2786, Validation Loss: 1.9732\nEpoch 108/1000, Train Loss: 0.3001, Validation Loss: 2.3215\nEpoch 109/1000, Train Loss: 0.3058, Validation Loss: 2.1096\nEpoch 110/1000, Train Loss: 0.2807, Validation Loss: 1.7883\nEpoch 111/1000, Train Loss: 0.2601, Validation Loss: 2.2999\nEpoch 112/1000, Train Loss: 0.2856, Validation Loss: 2.4525\nEpoch 113/1000, Train Loss: 0.2885, Validation Loss: 2.8074\nEpoch 114/1000, Train Loss: 0.3186, Validation Loss: 2.2618\nEpoch 115/1000, Train Loss: 0.2431, Validation Loss: 1.8476\nEpoch 116/1000, Train Loss: 0.2629, Validation Loss: 1.8352\nEpoch 117/1000, Train Loss: 0.2301, Validation Loss: 2.2520\nEpoch 118/1000, Train Loss: 0.2666, Validation Loss: 2.0160\nEpoch 119/1000, Train Loss: 0.2665, Validation Loss: 1.9392\nEpoch 120/1000, Train Loss: 0.2458, Validation Loss: 1.7907\nEpoch 121/1000, Train Loss: 0.3231, Validation Loss: 1.6696\nEpoch 122/1000, Train Loss: 0.3472, Validation Loss: 2.4069\nEpoch 123/1000, Train Loss: 0.2991, Validation Loss: 2.3756\nEpoch 124/1000, Train Loss: 0.2528, Validation Loss: 2.3051\nEpoch 125/1000, Train Loss: 0.3886, Validation Loss: 3.8189\nEpoch 126/1000, Train Loss: 0.2683, Validation Loss: 2.4112\nEpoch 127/1000, Train Loss: 0.3493, Validation Loss: 2.1216\nEpoch 128/1000, Train Loss: 0.3458, Validation Loss: 2.4031\nEpoch 129/1000, Train Loss: 0.2868, Validation Loss: 2.0917\nEpoch 130/1000, Train Loss: 0.2459, Validation Loss: 1.8879\nEpoch 131/1000, Train Loss: 0.2284, Validation Loss: 2.3393\nEpoch 132/1000, Train Loss: 0.2274, Validation Loss: 2.0558\nEpoch 133/1000, Train Loss: 0.2071, Validation Loss: 2.1109\nEpoch 134/1000, Train Loss: 0.2268, Validation Loss: 2.0861\nEpoch 135/1000, Train Loss: 0.2940, Validation Loss: 3.8410\nEpoch 136/1000, Train Loss: 0.3443, Validation Loss: 2.8489\nEpoch 137/1000, Train Loss: 0.4017, Validation Loss: 3.3191\nEpoch 138/1000, Train Loss: 0.3685, Validation Loss: 5.5646\nEpoch 139/1000, Train Loss: 0.2934, Validation Loss: 2.9098\nEpoch 140/1000, Train Loss: 0.2694, Validation Loss: 2.5849\nEpoch 141/1000, Train Loss: 0.4646, Validation Loss: 4.5206\nEpoch 142/1000, Train Loss: 0.5294, Validation Loss: 2.9608\nEpoch 143/1000, Train Loss: 0.3038, Validation Loss: 2.6665\nEpoch 144/1000, Train Loss: 0.2416, Validation Loss: 2.5697\nEpoch 145/1000, Train Loss: 0.2223, Validation Loss: 1.9007\nEpoch 146/1000, Train Loss: 0.2066, Validation Loss: 2.2103\nEpoch 147/1000, Train Loss: 0.1886, Validation Loss: 1.9623\nEpoch 148/1000, Train Loss: 0.1803, Validation Loss: 1.9180\nEpoch 149/1000, Train Loss: 0.1842, Validation Loss: 1.9131\nEpoch 150/1000, Train Loss: 0.1838, Validation Loss: 1.9227\nEpoch 151/1000, Train Loss: 0.2071, Validation Loss: 2.0938\nEpoch 152/1000, Train Loss: 0.1955, Validation Loss: 1.7815\nEpoch 153/1000, Train Loss: 0.1976, Validation Loss: 1.8728\nEpoch 154/1000, Train Loss: 0.1826, Validation Loss: 1.9772\nEpoch 155/1000, Train Loss: 0.2339, Validation Loss: 1.7999\nEpoch 156/1000, Train Loss: 0.1790, Validation Loss: 1.6661\nEpoch 157/1000, Train Loss: 0.3428, Validation Loss: 2.8121\nEpoch 158/1000, Train Loss: 0.2982, Validation Loss: 2.6361\nEpoch 159/1000, Train Loss: 0.2801, Validation Loss: 2.0572\nEpoch 160/1000, Train Loss: 0.2887, Validation Loss: 1.8024\nEpoch 161/1000, Train Loss: 0.2606, Validation Loss: 1.6017\nEpoch 162/1000, Train Loss: 0.2270, Validation Loss: 2.4797\nEpoch 163/1000, Train Loss: 0.2376, Validation Loss: 2.1878\nEpoch 164/1000, Train Loss: 0.2773, Validation Loss: 2.2384\nEpoch 165/1000, Train Loss: 0.2180, Validation Loss: 2.4827\nEpoch 166/1000, Train Loss: 0.2002, Validation Loss: 1.3890\nEpoch 167/1000, Train Loss: 0.2833, Validation Loss: 2.9389\nEpoch 168/1000, Train Loss: 0.2469, Validation Loss: 1.6915\nEpoch 169/1000, Train Loss: 0.2145, Validation Loss: 1.9208\nEpoch 170/1000, Train Loss: 0.1817, Validation Loss: 1.7107\nEpoch 171/1000, Train Loss: 0.1835, Validation Loss: 1.7688\nEpoch 172/1000, Train Loss: 0.2200, Validation Loss: 2.2587\nEpoch 173/1000, Train Loss: 0.1968, Validation Loss: 3.9021\nEpoch 174/1000, Train Loss: 0.3636, Validation Loss: 2.9723\nEpoch 175/1000, Train Loss: 0.2871, Validation Loss: 2.4409\nEpoch 176/1000, Train Loss: 0.1762, Validation Loss: 2.1818\nEpoch 177/1000, Train Loss: 0.1911, Validation Loss: 2.4583\nEpoch 178/1000, Train Loss: 0.1647, Validation Loss: 1.9349\nEpoch 179/1000, Train Loss: 0.1934, Validation Loss: 1.7348\nEpoch 180/1000, Train Loss: 0.1689, Validation Loss: 2.0841\nEpoch 181/1000, Train Loss: 0.1975, Validation Loss: 2.0885\nEpoch 182/1000, Train Loss: 0.2419, Validation Loss: 2.5770\nEpoch 183/1000, Train Loss: 0.3375, Validation Loss: 10.9935\nEpoch 184/1000, Train Loss: 0.2705, Validation Loss: 4.2411\nEpoch 185/1000, Train Loss: 0.2025, Validation Loss: 8.3908\nEpoch 186/1000, Train Loss: 0.2028, Validation Loss: 2.7197\nEpoch 187/1000, Train Loss: 0.2056, Validation Loss: 3.7605\nEpoch 188/1000, Train Loss: 0.2516, Validation Loss: 8.2540\nEpoch 189/1000, Train Loss: 0.2240, Validation Loss: 4.0955\nEpoch 190/1000, Train Loss: 0.2083, Validation Loss: 3.3384\nEpoch 191/1000, Train Loss: 0.1785, Validation Loss: 3.3374\nEpoch 192/1000, Train Loss: 0.1724, Validation Loss: 2.7045\nEpoch 193/1000, Train Loss: 0.1747, Validation Loss: 3.2296\nEpoch 194/1000, Train Loss: 0.1894, Validation Loss: 2.2055\nEpoch 195/1000, Train Loss: 0.1846, Validation Loss: 1.9789\nEpoch 196/1000, Train Loss: 0.1547, Validation Loss: 2.1003\nEpoch 197/1000, Train Loss: 0.1748, Validation Loss: 2.2535\nEpoch 198/1000, Train Loss: 0.2350, Validation Loss: 2.7058\nEpoch 199/1000, Train Loss: 0.2313, Validation Loss: 2.9333\nEpoch 200/1000, Train Loss: 0.2237, Validation Loss: 2.4601\nEpoch 201/1000, Train Loss: 0.4013, Validation Loss: 3.3031\nEpoch 202/1000, Train Loss: 0.4738, Validation Loss: 3.4555\nEpoch 203/1000, Train Loss: 0.3152, Validation Loss: 4.3751\nEpoch 204/1000, Train Loss: 0.2745, Validation Loss: 2.6948\nEpoch 205/1000, Train Loss: 0.1819, Validation Loss: 2.4968\nEpoch 206/1000, Train Loss: 0.1653, Validation Loss: 2.3703\nEpoch 207/1000, Train Loss: 0.1407, Validation Loss: 2.1610\nEpoch 208/1000, Train Loss: 0.1405, Validation Loss: 2.4086\nEpoch 209/1000, Train Loss: 0.1790, Validation Loss: 2.2205\nEpoch 210/1000, Train Loss: 0.1489, Validation Loss: 2.3126\nEpoch 211/1000, Train Loss: 0.1527, Validation Loss: 1.9964\nEpoch 212/1000, Train Loss: 0.1685, Validation Loss: 2.3937\nEpoch 213/1000, Train Loss: 0.2578, Validation Loss: 2.1128\nEpoch 214/1000, Train Loss: 0.1952, Validation Loss: 2.4961\nEpoch 215/1000, Train Loss: 0.1453, Validation Loss: 2.4926\nEpoch 216/1000, Train Loss: 0.1373, Validation Loss: 2.4918\nEpoch 217/1000, Train Loss: 0.1371, Validation Loss: 3.2339\nEpoch 218/1000, Train Loss: 0.2645, Validation Loss: 2.3837\nEpoch 219/1000, Train Loss: 0.1947, Validation Loss: 2.7385\nEpoch 220/1000, Train Loss: 0.2121, Validation Loss: 2.3057\nEpoch 221/1000, Train Loss: 0.2328, Validation Loss: 2.6450\nEpoch 222/1000, Train Loss: 0.2059, Validation Loss: 2.7456\nEpoch 223/1000, Train Loss: 0.1612, Validation Loss: 2.7158\nEpoch 224/1000, Train Loss: 0.2675, Validation Loss: 2.6869\nEpoch 225/1000, Train Loss: 0.1385, Validation Loss: 2.3369\nEpoch 226/1000, Train Loss: 0.1393, Validation Loss: 1.7908\nEpoch 227/1000, Train Loss: 0.1487, Validation Loss: 2.0816\nEpoch 228/1000, Train Loss: 0.2078, Validation Loss: 1.6837\nEpoch 229/1000, Train Loss: 0.1605, Validation Loss: 1.4520\nEpoch 230/1000, Train Loss: 0.2302, Validation Loss: 1.8378\nEpoch 231/1000, Train Loss: 0.1639, Validation Loss: 2.4277\nEpoch 232/1000, Train Loss: 0.1438, Validation Loss: 2.4435\nEpoch 233/1000, Train Loss: 0.1446, Validation Loss: 2.3327\nEpoch 234/1000, Train Loss: 0.2475, Validation Loss: 1.8091\nEpoch 235/1000, Train Loss: 0.2008, Validation Loss: 4.6956\nEpoch 236/1000, Train Loss: 0.1714, Validation Loss: 2.3803\nEpoch 237/1000, Train Loss: 0.4095, Validation Loss: 1.9058\nEpoch 238/1000, Train Loss: 0.5070, Validation Loss: 5.6051\nEpoch 239/1000, Train Loss: 0.4609, Validation Loss: 3.9960\nEpoch 240/1000, Train Loss: 0.3246, Validation Loss: 3.9133\nEpoch 241/1000, Train Loss: 0.2069, Validation Loss: 4.9556\nEpoch 242/1000, Train Loss: 0.1507, Validation Loss: 3.0507\nEpoch 243/1000, Train Loss: 0.1827, Validation Loss: 6.7769\nEpoch 244/1000, Train Loss: 0.2881, Validation Loss: 8.1527\nEpoch 245/1000, Train Loss: 0.1966, Validation Loss: 6.7473\nEpoch 246/1000, Train Loss: 0.1867, Validation Loss: 5.7810\nEpoch 247/1000, Train Loss: 0.1942, Validation Loss: 6.4448\nEpoch 248/1000, Train Loss: 0.1844, Validation Loss: 4.5654\nEpoch 249/1000, Train Loss: 0.1826, Validation Loss: 5.4508\nEpoch 250/1000, Train Loss: 0.1636, Validation Loss: 5.7677\nEpoch 251/1000, Train Loss: 0.1676, Validation Loss: 5.4931\nEpoch 252/1000, Train Loss: 0.1452, Validation Loss: 4.2608\nEpoch 253/1000, Train Loss: 0.1477, Validation Loss: 3.1334\nEpoch 254/1000, Train Loss: 0.2348, Validation Loss: 3.7563\nEpoch 255/1000, Train Loss: 0.1512, Validation Loss: 2.9424\nEpoch 256/1000, Train Loss: 0.1255, Validation Loss: 3.3347\nEpoch 257/1000, Train Loss: 0.1455, Validation Loss: 3.0176\nEpoch 258/1000, Train Loss: 0.1277, Validation Loss: 2.8835\nEpoch 259/1000, Train Loss: 0.1564, Validation Loss: 2.6389\nEpoch 260/1000, Train Loss: 0.1200, Validation Loss: 2.7831\nEpoch 261/1000, Train Loss: 0.1296, Validation Loss: 2.7193\nEpoch 262/1000, Train Loss: 0.1310, Validation Loss: 2.0296\nEpoch 263/1000, Train Loss: 0.1342, Validation Loss: 2.8403\nEpoch 264/1000, Train Loss: 0.1730, Validation Loss: 3.8633\nEpoch 265/1000, Train Loss: 0.1699, Validation Loss: 3.6426\nEpoch 266/1000, Train Loss: 0.1349, Validation Loss: 3.6539\nEpoch 267/1000, Train Loss: 0.1180, Validation Loss: 3.9817\nEpoch 268/1000, Train Loss: 0.1173, Validation Loss: 3.4686\nEpoch 269/1000, Train Loss: 0.1457, Validation Loss: 3.1670\nEpoch 270/1000, Train Loss: 0.2268, Validation Loss: 3.1521\nEpoch 271/1000, Train Loss: 0.2284, Validation Loss: 4.2783\nEpoch 272/1000, Train Loss: 0.3270, Validation Loss: 5.4562\nEpoch 273/1000, Train Loss: 0.4781, Validation Loss: 6.3633\nEpoch 274/1000, Train Loss: 0.3694, Validation Loss: 5.8703\nEpoch 275/1000, Train Loss: 0.3399, Validation Loss: 5.4698\nEpoch 276/1000, Train Loss: 0.2415, Validation Loss: 5.4428\nEpoch 277/1000, Train Loss: 0.2017, Validation Loss: 5.1593\nEpoch 278/1000, Train Loss: 0.2325, Validation Loss: 4.9986\nEpoch 279/1000, Train Loss: 0.1666, Validation Loss: 4.9092\nEpoch 280/1000, Train Loss: 0.1607, Validation Loss: 4.4662\nEpoch 281/1000, Train Loss: 0.1370, Validation Loss: 4.7901\nEpoch 282/1000, Train Loss: 0.1009, Validation Loss: 4.2681\nEpoch 283/1000, Train Loss: 0.1094, Validation Loss: 3.7055\nEpoch 284/1000, Train Loss: 0.0974, Validation Loss: 4.0320\nEpoch 285/1000, Train Loss: 0.1492, Validation Loss: 4.0031\nEpoch 286/1000, Train Loss: 0.1041, Validation Loss: 3.4386\nEpoch 287/1000, Train Loss: 0.0962, Validation Loss: 4.0521\nEpoch 288/1000, Train Loss: 0.1097, Validation Loss: 4.4014\nEpoch 289/1000, Train Loss: 0.1732, Validation Loss: 5.1907\nEpoch 290/1000, Train Loss: 0.3358, Validation Loss: 9.0255\nEpoch 291/1000, Train Loss: 0.2911, Validation Loss: 7.2891\nEpoch 292/1000, Train Loss: 0.3469, Validation Loss: 5.5760\nEpoch 293/1000, Train Loss: 0.1976, Validation Loss: 5.4397\nEpoch 294/1000, Train Loss: 0.1570, Validation Loss: 5.3418\nEpoch 295/1000, Train Loss: 0.1225, Validation Loss: 5.0601\nEpoch 296/1000, Train Loss: 0.1185, Validation Loss: 4.3420\nEpoch 297/1000, Train Loss: 0.1136, Validation Loss: 3.7700\nEpoch 298/1000, Train Loss: 0.2499, Validation Loss: 1.9909\nEpoch 299/1000, Train Loss: 0.1236, Validation Loss: 2.6183\nEpoch 300/1000, Train Loss: 0.2235, Validation Loss: 3.3009\nEpoch 301/1000, Train Loss: 0.2443, Validation Loss: 3.0805\nEpoch 302/1000, Train Loss: 0.2025, Validation Loss: 3.7695\nEpoch 303/1000, Train Loss: 0.1513, Validation Loss: 4.4318\nEpoch 304/1000, Train Loss: 0.1291, Validation Loss: 3.8424\nEpoch 305/1000, Train Loss: 0.1324, Validation Loss: 3.5351\nEpoch 306/1000, Train Loss: 0.1015, Validation Loss: 3.9858\nEpoch 307/1000, Train Loss: 0.1148, Validation Loss: 3.4124\nEpoch 308/1000, Train Loss: 0.1211, Validation Loss: 2.8929\nEpoch 309/1000, Train Loss: 0.1521, Validation Loss: 3.0853\nEpoch 310/1000, Train Loss: 0.2189, Validation Loss: 4.6669\nEpoch 311/1000, Train Loss: 0.3071, Validation Loss: 3.5201\nEpoch 312/1000, Train Loss: 0.2052, Validation Loss: 5.4790\nEpoch 313/1000, Train Loss: 0.2470, Validation Loss: 4.1760\nEpoch 314/1000, Train Loss: 0.3000, Validation Loss: 3.1525\nEpoch 315/1000, Train Loss: 0.3170, Validation Loss: 4.4597\nEpoch 316/1000, Train Loss: 0.2470, Validation Loss: 3.7647\nEpoch 317/1000, Train Loss: 0.1661, Validation Loss: 1.8760\nEpoch 318/1000, Train Loss: 0.1618, Validation Loss: 2.8224\nEpoch 319/1000, Train Loss: 0.1627, Validation Loss: 2.9127\nEpoch 320/1000, Train Loss: 0.1033, Validation Loss: 2.4993\nEpoch 321/1000, Train Loss: 0.0884, Validation Loss: 2.7567\nEpoch 322/1000, Train Loss: 0.1050, Validation Loss: 2.9753\nEpoch 323/1000, Train Loss: 0.1056, Validation Loss: 2.3296\nEpoch 324/1000, Train Loss: 0.0947, Validation Loss: 2.2348\nEpoch 325/1000, Train Loss: 0.1058, Validation Loss: 1.9939\nEpoch 326/1000, Train Loss: 0.2154, Validation Loss: 2.0201\nEpoch 327/1000, Train Loss: 0.1781, Validation Loss: 3.0858\nEpoch 328/1000, Train Loss: 0.1246, Validation Loss: 2.8613\nEpoch 329/1000, Train Loss: 0.1365, Validation Loss: 2.5294\nEpoch 330/1000, Train Loss: 0.0914, Validation Loss: 3.3483\nEpoch 331/1000, Train Loss: 0.1147, Validation Loss: 3.1874\nEpoch 332/1000, Train Loss: 0.0944, Validation Loss: 2.4226\nEpoch 333/1000, Train Loss: 0.1272, Validation Loss: 2.7765\nEpoch 334/1000, Train Loss: 0.2836, Validation Loss: 3.2764\nEpoch 335/1000, Train Loss: 0.2281, Validation Loss: 3.2195\nEpoch 336/1000, Train Loss: 0.1552, Validation Loss: 2.8677\nEpoch 337/1000, Train Loss: 0.3194, Validation Loss: 10.9857\nEpoch 338/1000, Train Loss: 0.4537, Validation Loss: 10.9955\nEpoch 339/1000, Train Loss: 0.2670, Validation Loss: 7.4528\nEpoch 340/1000, Train Loss: 0.1999, Validation Loss: 6.1161\nEpoch 341/1000, Train Loss: 0.1347, Validation Loss: 3.8479\nEpoch 342/1000, Train Loss: 0.1274, Validation Loss: 5.1151\nEpoch 343/1000, Train Loss: 0.1172, Validation Loss: 3.8445\nEpoch 344/1000, Train Loss: 0.1013, Validation Loss: 3.8486\nEpoch 345/1000, Train Loss: 0.0975, Validation Loss: 4.1968\nEpoch 346/1000, Train Loss: 0.0830, Validation Loss: 4.5702\nEpoch 347/1000, Train Loss: 0.1030, Validation Loss: 4.4961\nEpoch 348/1000, Train Loss: 0.1116, Validation Loss: 3.2134\nEpoch 349/1000, Train Loss: 0.0863, Validation Loss: 3.6067\nEpoch 350/1000, Train Loss: 0.0914, Validation Loss: 3.2275\nEpoch 351/1000, Train Loss: 0.1610, Validation Loss: 4.5134\nEpoch 352/1000, Train Loss: 0.2787, Validation Loss: 4.1816\nEpoch 353/1000, Train Loss: 0.1590, Validation Loss: 3.8351\nEpoch 354/1000, Train Loss: 0.1065, Validation Loss: 3.2442\nEpoch 355/1000, Train Loss: 0.0809, Validation Loss: 4.0523\nEpoch 356/1000, Train Loss: 0.1101, Validation Loss: 2.8932\nEpoch 357/1000, Train Loss: 0.1811, Validation Loss: 2.8902\nEpoch 358/1000, Train Loss: 0.1611, Validation Loss: 2.9279\nEpoch 359/1000, Train Loss: 0.3461, Validation Loss: 9.7346\nEpoch 360/1000, Train Loss: 0.3496, Validation Loss: 13.4435\nEpoch 361/1000, Train Loss: 0.2053, Validation Loss: 6.1676\nEpoch 362/1000, Train Loss: 0.2089, Validation Loss: 8.2288\nEpoch 363/1000, Train Loss: 0.3778, Validation Loss: 5.4869\nEpoch 364/1000, Train Loss: 0.2358, Validation Loss: 4.6442\nEpoch 365/1000, Train Loss: 0.1503, Validation Loss: 4.1260\nEpoch 366/1000, Train Loss: 0.1252, Validation Loss: 3.7753\nEpoch 367/1000, Train Loss: 0.1543, Validation Loss: 4.0720\nEpoch 368/1000, Train Loss: 0.1096, Validation Loss: 4.3235\nEpoch 369/1000, Train Loss: 0.0812, Validation Loss: 4.4223\nEpoch 370/1000, Train Loss: 0.0784, Validation Loss: 4.1394\nEpoch 371/1000, Train Loss: 0.1147, Validation Loss: 4.5960\nEpoch 372/1000, Train Loss: 0.0927, Validation Loss: 4.1494\nEpoch 373/1000, Train Loss: 0.1077, Validation Loss: 3.3061\nEpoch 374/1000, Train Loss: 0.0791, Validation Loss: 3.9484\nEpoch 375/1000, Train Loss: 0.1016, Validation Loss: 3.9866\nEpoch 376/1000, Train Loss: 0.1007, Validation Loss: 4.5516\nEpoch 377/1000, Train Loss: 0.0864, Validation Loss: 3.9098\nEpoch 378/1000, Train Loss: 0.0964, Validation Loss: 4.5267\nEpoch 379/1000, Train Loss: 0.1275, Validation Loss: 3.6792\nEpoch 380/1000, Train Loss: 0.2129, Validation Loss: 3.4841\nEpoch 381/1000, Train Loss: 0.2843, Validation Loss: 3.7142\nEpoch 382/1000, Train Loss: 0.3416, Validation Loss: 3.4848\nEpoch 383/1000, Train Loss: 0.2644, Validation Loss: 4.4141\nEpoch 384/1000, Train Loss: 0.2250, Validation Loss: 3.8163\nEpoch 385/1000, Train Loss: 0.1723, Validation Loss: 4.1323\nEpoch 386/1000, Train Loss: 0.1234, Validation Loss: 3.3198\nEpoch 387/1000, Train Loss: 0.1333, Validation Loss: 2.9100\nEpoch 388/1000, Train Loss: 0.1029, Validation Loss: 3.3952\nEpoch 389/1000, Train Loss: 0.0759, Validation Loss: 3.3845\nEpoch 390/1000, Train Loss: 0.1671, Validation Loss: 3.6924\nEpoch 391/1000, Train Loss: 0.2112, Validation Loss: 3.1950\nEpoch 392/1000, Train Loss: 0.3337, Validation Loss: 5.7358\nEpoch 393/1000, Train Loss: 0.5071, Validation Loss: 12.0435\nEpoch 394/1000, Train Loss: 0.2544, Validation Loss: 4.1799\nEpoch 395/1000, Train Loss: 0.2068, Validation Loss: 9.1975\nEpoch 396/1000, Train Loss: 0.1247, Validation Loss: 4.0134\nEpoch 397/1000, Train Loss: 0.0948, Validation Loss: 3.9274\nEpoch 398/1000, Train Loss: 0.1036, Validation Loss: 4.1137\nEpoch 399/1000, Train Loss: 0.1706, Validation Loss: 12.0273\nEpoch 400/1000, Train Loss: 0.1135, Validation Loss: 4.2200\nEpoch 401/1000, Train Loss: 0.0798, Validation Loss: 5.1229\nEpoch 402/1000, Train Loss: 0.0805, Validation Loss: 5.8152\nEpoch 403/1000, Train Loss: 0.0749, Validation Loss: 6.0641\nEpoch 404/1000, Train Loss: 0.0922, Validation Loss: 4.7941\nEpoch 405/1000, Train Loss: 0.0964, Validation Loss: 4.8038\nEpoch 406/1000, Train Loss: 0.0877, Validation Loss: 5.2385\nEpoch 407/1000, Train Loss: 0.0815, Validation Loss: 4.6254\nEpoch 408/1000, Train Loss: 0.0707, Validation Loss: 4.4724\nEpoch 409/1000, Train Loss: 0.0722, Validation Loss: 4.2790\nEpoch 410/1000, Train Loss: 0.0947, Validation Loss: 4.3850\nEpoch 411/1000, Train Loss: 0.1052, Validation Loss: 4.9157\nEpoch 412/1000, Train Loss: 0.0811, Validation Loss: 5.2790\nEpoch 413/1000, Train Loss: 0.1293, Validation Loss: 4.1969\nEpoch 414/1000, Train Loss: 0.2030, Validation Loss: 2.1327\nEpoch 415/1000, Train Loss: 0.6249, Validation Loss: 9.9702\nEpoch 416/1000, Train Loss: 0.8421, Validation Loss: 13.9630\nEpoch 417/1000, Train Loss: 0.4139, Validation Loss: 10.3942\nEpoch 418/1000, Train Loss: 0.2461, Validation Loss: 11.2871\nEpoch 419/1000, Train Loss: 0.1036, Validation Loss: 9.6742\nEpoch 420/1000, Train Loss: 0.1060, Validation Loss: 10.4735\nEpoch 421/1000, Train Loss: 0.1045, Validation Loss: 8.8375\nEpoch 422/1000, Train Loss: 0.1243, Validation Loss: 5.8481\nEpoch 423/1000, Train Loss: 0.1135, Validation Loss: 4.0485\nEpoch 424/1000, Train Loss: 0.1133, Validation Loss: 7.9684\nEpoch 425/1000, Train Loss: 0.1225, Validation Loss: 7.5668\nEpoch 426/1000, Train Loss: 0.0830, Validation Loss: 7.0993\nEpoch 427/1000, Train Loss: 0.0781, Validation Loss: 6.2858\nEpoch 428/1000, Train Loss: 0.0973, Validation Loss: 4.6782\nEpoch 429/1000, Train Loss: 0.0729, Validation Loss: 5.6272\nEpoch 430/1000, Train Loss: 0.1043, Validation Loss: 4.5776\nEpoch 431/1000, Train Loss: 0.1233, Validation Loss: 5.2480\nEpoch 432/1000, Train Loss: 0.2181, Validation Loss: 7.4865\nEpoch 433/1000, Train Loss: 0.2304, Validation Loss: 8.7936\nEpoch 434/1000, Train Loss: 0.3634, Validation Loss: 5.0160\nEpoch 435/1000, Train Loss: 0.2385, Validation Loss: 7.9439\nEpoch 436/1000, Train Loss: 0.1900, Validation Loss: 6.4779\nEpoch 437/1000, Train Loss: 0.1523, Validation Loss: 8.8469\nEpoch 438/1000, Train Loss: 0.1633, Validation Loss: 7.2708\nEpoch 439/1000, Train Loss: 0.1173, Validation Loss: 6.6550\nEpoch 440/1000, Train Loss: 0.1567, Validation Loss: 6.7451\nEpoch 441/1000, Train Loss: 0.0891, Validation Loss: 6.0746\nEpoch 442/1000, Train Loss: 0.0984, Validation Loss: 4.8872\nEpoch 443/1000, Train Loss: 0.1782, Validation Loss: 6.6508\nEpoch 444/1000, Train Loss: 0.3204, Validation Loss: 11.3685\nEpoch 445/1000, Train Loss: 0.2803, Validation Loss: 3.3989\nEpoch 446/1000, Train Loss: 0.2045, Validation Loss: 10.4049\nEpoch 447/1000, Train Loss: 0.1892, Validation Loss: 6.5558\nEpoch 448/1000, Train Loss: 0.1415, Validation Loss: 3.9228\nEpoch 449/1000, Train Loss: 0.1494, Validation Loss: 4.5141\nEpoch 450/1000, Train Loss: 0.0918, Validation Loss: 6.6727\nEpoch 451/1000, Train Loss: 0.1242, Validation Loss: 5.7555\nEpoch 452/1000, Train Loss: 0.0927, Validation Loss: 3.9635\nEpoch 453/1000, Train Loss: 0.0822, Validation Loss: 4.5104\nEpoch 454/1000, Train Loss: 0.0702, Validation Loss: 3.8157\nEpoch 455/1000, Train Loss: 0.0683, Validation Loss: 3.9341\nEpoch 456/1000, Train Loss: 0.0997, Validation Loss: 4.4239\nEpoch 457/1000, Train Loss: 0.2170, Validation Loss: 4.2399\nEpoch 458/1000, Train Loss: 0.1975, Validation Loss: 2.3582\nEpoch 459/1000, Train Loss: 0.1375, Validation Loss: 2.7518\nEpoch 460/1000, Train Loss: 0.1089, Validation Loss: 2.9346\nEpoch 461/1000, Train Loss: 0.1090, Validation Loss: 2.5473\nEpoch 462/1000, Train Loss: 0.1185, Validation Loss: 2.1999\nEpoch 463/1000, Train Loss: 0.1022, Validation Loss: 2.9323\nEpoch 464/1000, Train Loss: 0.2895, Validation Loss: 14.4290\nEpoch 465/1000, Train Loss: 0.3254, Validation Loss: 2.8747\nEpoch 466/1000, Train Loss: 0.1374, Validation Loss: 2.4951\nEpoch 467/1000, Train Loss: 0.0959, Validation Loss: 2.5761\nEpoch 468/1000, Train Loss: 0.0827, Validation Loss: 2.6021\nEpoch 469/1000, Train Loss: 0.0938, Validation Loss: 2.4791\nEpoch 470/1000, Train Loss: 0.0979, Validation Loss: 2.7625\nEpoch 471/1000, Train Loss: 0.0950, Validation Loss: 3.0245\nEpoch 472/1000, Train Loss: 0.1162, Validation Loss: 2.3498\nEpoch 473/1000, Train Loss: 0.1227, Validation Loss: 3.0815\nEpoch 474/1000, Train Loss: 0.1156, Validation Loss: 4.1790\nEpoch 475/1000, Train Loss: 0.0764, Validation Loss: 3.3113\nEpoch 476/1000, Train Loss: 0.1234, Validation Loss: 3.6437\nEpoch 477/1000, Train Loss: 0.0888, Validation Loss: 2.7733\nEpoch 478/1000, Train Loss: 0.1059, Validation Loss: 2.3005\nEpoch 479/1000, Train Loss: 0.1459, Validation Loss: 2.5981\nEpoch 480/1000, Train Loss: 0.1664, Validation Loss: 3.3209\nEpoch 481/1000, Train Loss: 0.1031, Validation Loss: 3.1608\nEpoch 482/1000, Train Loss: 0.1452, Validation Loss: 3.5211\nEpoch 483/1000, Train Loss: 0.1552, Validation Loss: 3.2779\nEpoch 484/1000, Train Loss: 0.1328, Validation Loss: 2.4329\nEpoch 485/1000, Train Loss: 0.0812, Validation Loss: 3.4362\nEpoch 486/1000, Train Loss: 0.0985, Validation Loss: 2.9761\nEpoch 487/1000, Train Loss: 0.2356, Validation Loss: 3.3223\nEpoch 488/1000, Train Loss: 0.1601, Validation Loss: 4.0645\nEpoch 489/1000, Train Loss: 0.1699, Validation Loss: 3.1760\nEpoch 490/1000, Train Loss: 0.2550, Validation Loss: 4.4282\nEpoch 491/1000, Train Loss: 0.3739, Validation Loss: 3.4082\nEpoch 492/1000, Train Loss: 0.3582, Validation Loss: 1.6714\nEpoch 493/1000, Train Loss: 0.3305, Validation Loss: 3.0539\nEpoch 494/1000, Train Loss: 0.1734, Validation Loss: 3.4234\nEpoch 495/1000, Train Loss: 0.1769, Validation Loss: 2.0704\nEpoch 496/1000, Train Loss: 0.1688, Validation Loss: 3.6958\nEpoch 497/1000, Train Loss: 0.1588, Validation Loss: 4.8560\nEpoch 498/1000, Train Loss: 0.1653, Validation Loss: 4.4623\nEpoch 499/1000, Train Loss: 0.1327, Validation Loss: 4.1263\nEpoch 500/1000, Train Loss: 0.0772, Validation Loss: 4.1941\nEpoch 501/1000, Train Loss: 0.0964, Validation Loss: 4.0038\nEpoch 502/1000, Train Loss: 0.0811, Validation Loss: 4.4488\nEpoch 503/1000, Train Loss: 0.0776, Validation Loss: 3.7503\nEpoch 504/1000, Train Loss: 0.0648, Validation Loss: 3.8134\nEpoch 505/1000, Train Loss: 0.0984, Validation Loss: 4.2710\nEpoch 506/1000, Train Loss: 0.0720, Validation Loss: 3.7472\nEpoch 507/1000, Train Loss: 0.0790, Validation Loss: 4.1065\nEpoch 508/1000, Train Loss: 0.0845, Validation Loss: 4.2376\nEpoch 509/1000, Train Loss: 0.0596, Validation Loss: 4.5232\nEpoch 510/1000, Train Loss: 0.1818, Validation Loss: 4.4530\nEpoch 511/1000, Train Loss: 0.2319, Validation Loss: 2.4936\nEpoch 512/1000, Train Loss: 0.1000, Validation Loss: 2.9327\nEpoch 513/1000, Train Loss: 0.0754, Validation Loss: 3.2354\nEpoch 514/1000, Train Loss: 0.0747, Validation Loss: 3.1520\nEpoch 515/1000, Train Loss: 0.0706, Validation Loss: 3.6909\nEpoch 516/1000, Train Loss: 0.0628, Validation Loss: 3.8995\nEpoch 517/1000, Train Loss: 0.0859, Validation Loss: 3.3135\nEpoch 518/1000, Train Loss: 0.0946, Validation Loss: 3.8202\nEpoch 519/1000, Train Loss: 0.0871, Validation Loss: 3.5284\nEpoch 520/1000, Train Loss: 0.0755, Validation Loss: 3.5139\nEpoch 521/1000, Train Loss: 0.1001, Validation Loss: 3.2053\nEpoch 522/1000, Train Loss: 0.1883, Validation Loss: 6.9503\nEpoch 523/1000, Train Loss: 0.2369, Validation Loss: 17.0276\nEpoch 524/1000, Train Loss: 0.3239, Validation Loss: 7.1507\nEpoch 525/1000, Train Loss: 0.3556, Validation Loss: 2.6414\nEpoch 526/1000, Train Loss: 0.1978, Validation Loss: 6.2604\nEpoch 527/1000, Train Loss: 0.2000, Validation Loss: 4.8061\nEpoch 528/1000, Train Loss: 0.1832, Validation Loss: 6.3307\nEpoch 529/1000, Train Loss: 0.3383, Validation Loss: 8.3261\nEpoch 530/1000, Train Loss: 0.2449, Validation Loss: 7.9954\nEpoch 531/1000, Train Loss: 0.1250, Validation Loss: 9.9534\nEpoch 532/1000, Train Loss: 0.1182, Validation Loss: 10.4412\nEpoch 533/1000, Train Loss: 0.0980, Validation Loss: 9.3665\nEpoch 534/1000, Train Loss: 0.0730, Validation Loss: 9.5306\nEpoch 535/1000, Train Loss: 0.1151, Validation Loss: 9.1682\nEpoch 536/1000, Train Loss: 0.0923, Validation Loss: 8.7632\nEpoch 537/1000, Train Loss: 0.0572, Validation Loss: 8.9911\nEpoch 538/1000, Train Loss: 0.0758, Validation Loss: 9.1143\nEpoch 539/1000, Train Loss: 0.0558, Validation Loss: 8.2763\nEpoch 540/1000, Train Loss: 0.0617, Validation Loss: 8.4372\nEpoch 541/1000, Train Loss: 0.0725, Validation Loss: 9.2713\nEpoch 542/1000, Train Loss: 0.1251, Validation Loss: 10.1723\nEpoch 543/1000, Train Loss: 0.1787, Validation Loss: 8.9040\nEpoch 544/1000, Train Loss: 0.1644, Validation Loss: 7.4461\nEpoch 545/1000, Train Loss: 0.2043, Validation Loss: 8.2692\nEpoch 546/1000, Train Loss: 0.2908, Validation Loss: 9.1989\nEpoch 547/1000, Train Loss: 0.3874, Validation Loss: 7.5292\nEpoch 548/1000, Train Loss: 0.1644, Validation Loss: 5.6388\nEpoch 549/1000, Train Loss: 0.0701, Validation Loss: 6.9799\nEpoch 550/1000, Train Loss: 0.0728, Validation Loss: 6.8381\nEpoch 551/1000, Train Loss: 0.0604, Validation Loss: 7.0883\nEpoch 552/1000, Train Loss: 0.0642, Validation Loss: 7.0798\nEpoch 553/1000, Train Loss: 0.0600, Validation Loss: 6.5682\nEpoch 554/1000, Train Loss: 0.0552, Validation Loss: 6.1753\nEpoch 555/1000, Train Loss: 0.0524, Validation Loss: 6.1730\nEpoch 556/1000, Train Loss: 0.0746, Validation Loss: 5.7353\nEpoch 557/1000, Train Loss: 0.0585, Validation Loss: 6.6124\nEpoch 558/1000, Train Loss: 0.0725, Validation Loss: 4.8922\nEpoch 559/1000, Train Loss: 0.1061, Validation Loss: 6.5059\nEpoch 560/1000, Train Loss: 0.1022, Validation Loss: 5.5319\nEpoch 561/1000, Train Loss: 0.1521, Validation Loss: 7.7135\nEpoch 562/1000, Train Loss: 0.3022, Validation Loss: 13.8794\nEpoch 563/1000, Train Loss: 0.4635, Validation Loss: 7.8166\nEpoch 564/1000, Train Loss: 0.6105, Validation Loss: 6.1444\nEpoch 565/1000, Train Loss: 0.2620, Validation Loss: 11.9083\nEpoch 566/1000, Train Loss: 0.1866, Validation Loss: 6.1870\nEpoch 567/1000, Train Loss: 0.1075, Validation Loss: 5.5939\nEpoch 568/1000, Train Loss: 0.0640, Validation Loss: 6.5021\nEpoch 569/1000, Train Loss: 0.0570, Validation Loss: 6.3815\nEpoch 570/1000, Train Loss: 0.0710, Validation Loss: 6.8558\nEpoch 571/1000, Train Loss: 0.0697, Validation Loss: 6.1697\nEpoch 572/1000, Train Loss: 0.0715, Validation Loss: 5.7630\nEpoch 573/1000, Train Loss: 0.0506, Validation Loss: 5.6769\nEpoch 574/1000, Train Loss: 0.0774, Validation Loss: 4.9875\nEpoch 575/1000, Train Loss: 0.0659, Validation Loss: 5.2507\nEpoch 576/1000, Train Loss: 0.0579, Validation Loss: 4.8829\nEpoch 577/1000, Train Loss: 0.1017, Validation Loss: 5.6301\nEpoch 578/1000, Train Loss: 0.1871, Validation Loss: 3.8140\nEpoch 579/1000, Train Loss: 0.2336, Validation Loss: 4.0065\nEpoch 580/1000, Train Loss: 0.2190, Validation Loss: 4.2415\nEpoch 581/1000, Train Loss: 0.2318, Validation Loss: 3.9232\nEpoch 582/1000, Train Loss: 0.2040, Validation Loss: 6.2056\nEpoch 583/1000, Train Loss: 0.1689, Validation Loss: 8.6375\nEpoch 584/1000, Train Loss: 0.1333, Validation Loss: 9.4616\nEpoch 585/1000, Train Loss: 0.0938, Validation Loss: 6.2733\nEpoch 586/1000, Train Loss: 0.0806, Validation Loss: 4.9047\nEpoch 587/1000, Train Loss: 0.0843, Validation Loss: 5.1945\nEpoch 588/1000, Train Loss: 0.0512, Validation Loss: 5.1129\nEpoch 589/1000, Train Loss: 0.0583, Validation Loss: 5.2987\nEpoch 590/1000, Train Loss: 0.0623, Validation Loss: 4.0871\nEpoch 591/1000, Train Loss: 0.0525, Validation Loss: 4.4992\nEpoch 592/1000, Train Loss: 0.0498, Validation Loss: 4.3794\nEpoch 593/1000, Train Loss: 0.1111, Validation Loss: 4.8554\nEpoch 594/1000, Train Loss: 0.1670, Validation Loss: 3.6697\nEpoch 595/1000, Train Loss: 0.4807, Validation Loss: 4.6383\nEpoch 596/1000, Train Loss: 0.2996, Validation Loss: 5.5995\nEpoch 597/1000, Train Loss: 0.1127, Validation Loss: 4.9793\nEpoch 598/1000, Train Loss: 0.0991, Validation Loss: 4.3603\nEpoch 599/1000, Train Loss: 0.1220, Validation Loss: 5.4509\nEpoch 600/1000, Train Loss: 0.0790, Validation Loss: 4.3313\nEpoch 601/1000, Train Loss: 0.0810, Validation Loss: 3.7915\nEpoch 602/1000, Train Loss: 0.0531, Validation Loss: 4.7638\nEpoch 603/1000, Train Loss: 0.0627, Validation Loss: 3.5825\nEpoch 604/1000, Train Loss: 0.0540, Validation Loss: 3.8197\nEpoch 605/1000, Train Loss: 0.0694, Validation Loss: 3.8914\nEpoch 606/1000, Train Loss: 0.0778, Validation Loss: 3.5975\nEpoch 607/1000, Train Loss: 0.0885, Validation Loss: 2.8111\nEpoch 608/1000, Train Loss: 0.0910, Validation Loss: 2.9072\nEpoch 609/1000, Train Loss: 0.1212, Validation Loss: 5.1537\nEpoch 610/1000, Train Loss: 0.2691, Validation Loss: 4.1765\nEpoch 611/1000, Train Loss: 0.1922, Validation Loss: 6.5991\nEpoch 612/1000, Train Loss: 0.1523, Validation Loss: 3.6186\nEpoch 613/1000, Train Loss: 0.0878, Validation Loss: 3.8876\nEpoch 614/1000, Train Loss: 0.0633, Validation Loss: 4.8960\nEpoch 615/1000, Train Loss: 0.0948, Validation Loss: 5.6468\nEpoch 616/1000, Train Loss: 0.2721, Validation Loss: 6.3287\nEpoch 617/1000, Train Loss: 0.2229, Validation Loss: 3.3304\nEpoch 618/1000, Train Loss: 0.2779, Validation Loss: 3.4270\nEpoch 619/1000, Train Loss: 0.2079, Validation Loss: 3.0751\nEpoch 620/1000, Train Loss: 0.0833, Validation Loss: 3.0189\nEpoch 621/1000, Train Loss: 0.0865, Validation Loss: 4.5776\nEpoch 622/1000, Train Loss: 0.0624, Validation Loss: 4.3725\nEpoch 623/1000, Train Loss: 0.0582, Validation Loss: 3.0992\nEpoch 624/1000, Train Loss: 0.0843, Validation Loss: 3.4852\nEpoch 625/1000, Train Loss: 0.0840, Validation Loss: 2.6546\nEpoch 626/1000, Train Loss: 0.1531, Validation Loss: 3.9869\nEpoch 627/1000, Train Loss: 0.1662, Validation Loss: 3.8623\nEpoch 628/1000, Train Loss: 0.0976, Validation Loss: 3.5332\nEpoch 629/1000, Train Loss: 0.0811, Validation Loss: 3.7356\nEpoch 630/1000, Train Loss: 0.0739, Validation Loss: 4.5423\nEpoch 631/1000, Train Loss: 0.0873, Validation Loss: 4.2900\nEpoch 632/1000, Train Loss: 0.0666, Validation Loss: 5.0557\nEpoch 633/1000, Train Loss: 0.0539, Validation Loss: 4.2411\nEpoch 634/1000, Train Loss: 0.0711, Validation Loss: 9.9394\nEpoch 635/1000, Train Loss: 0.1300, Validation Loss: 7.5210\nEpoch 636/1000, Train Loss: 0.2645, Validation Loss: 13.6420\nEpoch 637/1000, Train Loss: 0.6017, Validation Loss: 20.7162\nEpoch 638/1000, Train Loss: 0.8566, Validation Loss: 10.9210\nEpoch 639/1000, Train Loss: 0.3266, Validation Loss: 13.7806\nEpoch 640/1000, Train Loss: 0.2606, Validation Loss: 17.1912\nEpoch 641/1000, Train Loss: 0.2089, Validation Loss: 9.2114\nEpoch 642/1000, Train Loss: 0.0841, Validation Loss: 14.1046\nEpoch 643/1000, Train Loss: 0.0716, Validation Loss: 12.6907\nEpoch 644/1000, Train Loss: 0.0853, Validation Loss: 13.2005\nEpoch 645/1000, Train Loss: 0.0519, Validation Loss: 11.4910\nEpoch 646/1000, Train Loss: 0.0532, Validation Loss: 10.7799\nEpoch 647/1000, Train Loss: 0.0523, Validation Loss: 11.3218\nEpoch 648/1000, Train Loss: 0.0576, Validation Loss: 8.3679\nEpoch 649/1000, Train Loss: 0.0540, Validation Loss: 8.3389\nEpoch 650/1000, Train Loss: 0.0498, Validation Loss: 8.8098\nEpoch 651/1000, Train Loss: 0.0567, Validation Loss: 8.1464\nEpoch 652/1000, Train Loss: 0.0852, Validation Loss: 9.5258\nEpoch 653/1000, Train Loss: 0.0722, Validation Loss: 6.4889\nEpoch 654/1000, Train Loss: 0.0912, Validation Loss: 8.0942\nEpoch 655/1000, Train Loss: 0.0523, Validation Loss: 7.3695\nEpoch 656/1000, Train Loss: 0.0582, Validation Loss: 6.8119\nEpoch 657/1000, Train Loss: 0.0562, Validation Loss: 6.9997\nEpoch 658/1000, Train Loss: 0.0568, Validation Loss: 8.3237\nEpoch 659/1000, Train Loss: 0.2122, Validation Loss: 6.5285\nEpoch 660/1000, Train Loss: 0.1646, Validation Loss: 10.2900\nEpoch 661/1000, Train Loss: 0.1729, Validation Loss: 9.6192\nEpoch 662/1000, Train Loss: 0.1556, Validation Loss: 11.3981\nEpoch 663/1000, Train Loss: 0.0914, Validation Loss: 11.7144\nEpoch 664/1000, Train Loss: 0.1123, Validation Loss: 7.3080\nEpoch 665/1000, Train Loss: 0.0836, Validation Loss: 7.4883\nEpoch 666/1000, Train Loss: 0.0793, Validation Loss: 6.8357\nEpoch 667/1000, Train Loss: 0.1155, Validation Loss: 7.1660\nEpoch 668/1000, Train Loss: 0.1205, Validation Loss: 3.5394\nEpoch 669/1000, Train Loss: 0.1239, Validation Loss: 7.2930\nEpoch 670/1000, Train Loss: 0.1196, Validation Loss: 4.2706\nEpoch 671/1000, Train Loss: 0.0999, Validation Loss: 5.4041\nEpoch 672/1000, Train Loss: 0.3232, Validation Loss: 7.7195\nEpoch 673/1000, Train Loss: 0.2362, Validation Loss: 5.1776\nEpoch 674/1000, Train Loss: 0.1878, Validation Loss: 5.0074\nEpoch 675/1000, Train Loss: 0.1176, Validation Loss: 3.2560\nEpoch 676/1000, Train Loss: 0.0958, Validation Loss: 4.7618\nEpoch 677/1000, Train Loss: 0.1427, Validation Loss: 5.1975\nEpoch 678/1000, Train Loss: 0.1281, Validation Loss: 6.7061\nEpoch 679/1000, Train Loss: 0.0811, Validation Loss: 6.3972\nEpoch 680/1000, Train Loss: 0.0764, Validation Loss: 6.1476\nEpoch 681/1000, Train Loss: 0.0702, Validation Loss: 6.3273\nEpoch 682/1000, Train Loss: 0.1076, Validation Loss: 5.0237\nEpoch 683/1000, Train Loss: 0.1441, Validation Loss: 5.0215\nEpoch 684/1000, Train Loss: 0.1692, Validation Loss: 4.5644\nEpoch 685/1000, Train Loss: 0.1743, Validation Loss: 3.2279\nEpoch 686/1000, Train Loss: 0.1339, Validation Loss: 4.1886\nEpoch 687/1000, Train Loss: 0.1046, Validation Loss: 4.5860\nEpoch 688/1000, Train Loss: 0.0632, Validation Loss: 4.5315\nEpoch 689/1000, Train Loss: 0.0859, Validation Loss: 3.7424\nEpoch 690/1000, Train Loss: 0.0633, Validation Loss: 4.1581\nEpoch 691/1000, Train Loss: 0.0483, Validation Loss: 4.1460\nEpoch 692/1000, Train Loss: 0.0551, Validation Loss: 3.5222\nEpoch 693/1000, Train Loss: 0.0508, Validation Loss: 4.2373\nEpoch 694/1000, Train Loss: 0.0754, Validation Loss: 2.9519\nEpoch 695/1000, Train Loss: 0.5141, Validation Loss: 15.7767\nEpoch 696/1000, Train Loss: 0.6402, Validation Loss: 16.5330\nEpoch 697/1000, Train Loss: 0.3380, Validation Loss: 20.7901\nEpoch 698/1000, Train Loss: 0.2073, Validation Loss: 17.8237\nEpoch 699/1000, Train Loss: 0.0974, Validation Loss: 15.4243\nEpoch 700/1000, Train Loss: 0.0934, Validation Loss: 18.0925\nEpoch 701/1000, Train Loss: 0.0994, Validation Loss: 17.7831\nEpoch 702/1000, Train Loss: 0.1268, Validation Loss: 16.5242\nEpoch 703/1000, Train Loss: 0.0595, Validation Loss: 15.4180\nEpoch 704/1000, Train Loss: 0.0495, Validation Loss: 16.3365\nEpoch 705/1000, Train Loss: 0.0486, Validation Loss: 16.8997\nEpoch 706/1000, Train Loss: 0.0491, Validation Loss: 14.3689\nEpoch 707/1000, Train Loss: 0.0514, Validation Loss: 15.6295\nEpoch 708/1000, Train Loss: 0.0509, Validation Loss: 13.5926\nEpoch 709/1000, Train Loss: 0.0543, Validation Loss: 15.5359\nEpoch 710/1000, Train Loss: 0.0673, Validation Loss: 14.0850\nEpoch 711/1000, Train Loss: 0.0658, Validation Loss: 15.4819\nEpoch 712/1000, Train Loss: 0.0874, Validation Loss: 18.2384\nEpoch 713/1000, Train Loss: 0.0847, Validation Loss: 12.1569\nEpoch 714/1000, Train Loss: 0.0759, Validation Loss: 12.6276\nEpoch 715/1000, Train Loss: 0.0986, Validation Loss: 13.5524\nEpoch 716/1000, Train Loss: 0.0868, Validation Loss: 13.4494\nEpoch 717/1000, Train Loss: 0.1790, Validation Loss: 14.7932\nEpoch 718/1000, Train Loss: 0.3126, Validation Loss: 14.6460\nEpoch 719/1000, Train Loss: 0.3019, Validation Loss: 15.5507\nEpoch 720/1000, Train Loss: 0.1379, Validation Loss: 13.8323\nEpoch 721/1000, Train Loss: 0.0643, Validation Loss: 13.9649\nEpoch 722/1000, Train Loss: 0.0514, Validation Loss: 13.6214\nEpoch 723/1000, Train Loss: 0.0624, Validation Loss: 12.5114\nEpoch 724/1000, Train Loss: 0.0692, Validation Loss: 12.0855\nEpoch 725/1000, Train Loss: 0.0485, Validation Loss: 12.5366\nEpoch 726/1000, Train Loss: 0.0505, Validation Loss: 12.1684\nEpoch 727/1000, Train Loss: 0.0542, Validation Loss: 12.7320\nEpoch 728/1000, Train Loss: 0.0545, Validation Loss: 12.2604\nEpoch 729/1000, Train Loss: 0.0468, Validation Loss: 11.7194\nEpoch 730/1000, Train Loss: 0.0383, Validation Loss: 12.0867\nEpoch 731/1000, Train Loss: 0.0391, Validation Loss: 9.9611\nEpoch 732/1000, Train Loss: 0.0439, Validation Loss: 10.2129\nEpoch 733/1000, Train Loss: 0.0455, Validation Loss: 11.1001\nEpoch 734/1000, Train Loss: 0.2222, Validation Loss: 5.6366\nEpoch 735/1000, Train Loss: 0.2314, Validation Loss: 10.0307\nEpoch 736/1000, Train Loss: 0.1868, Validation Loss: 4.5497\nEpoch 737/1000, Train Loss: 0.1706, Validation Loss: 7.4068\nEpoch 738/1000, Train Loss: 0.1262, Validation Loss: 7.8203\nEpoch 739/1000, Train Loss: 0.1877, Validation Loss: 6.0435\nEpoch 740/1000, Train Loss: 0.2845, Validation Loss: 6.2745\nEpoch 741/1000, Train Loss: 0.1448, Validation Loss: 5.5270\nEpoch 742/1000, Train Loss: 0.0751, Validation Loss: 7.1236\nEpoch 743/1000, Train Loss: 0.0706, Validation Loss: 6.6058\nEpoch 744/1000, Train Loss: 0.0862, Validation Loss: 4.0979\nEpoch 745/1000, Train Loss: 0.0822, Validation Loss: 5.4255\nEpoch 746/1000, Train Loss: 0.0638, Validation Loss: 4.4990\nEpoch 747/1000, Train Loss: 0.0547, Validation Loss: 6.5200\nEpoch 748/1000, Train Loss: 0.0518, Validation Loss: 5.9175\nEpoch 749/1000, Train Loss: 0.0473, Validation Loss: 5.0126\nEpoch 750/1000, Train Loss: 0.0526, Validation Loss: 5.6803\nEpoch 751/1000, Train Loss: 0.0508, Validation Loss: 5.2771\nEpoch 752/1000, Train Loss: 0.0468, Validation Loss: 5.6967\nEpoch 753/1000, Train Loss: 0.0569, Validation Loss: 5.3415\nEpoch 754/1000, Train Loss: 0.1817, Validation Loss: 13.4357\nEpoch 755/1000, Train Loss: 0.2413, Validation Loss: 14.0809\nEpoch 756/1000, Train Loss: 0.3517, Validation Loss: 26.5344\nEpoch 757/1000, Train Loss: 0.1887, Validation Loss: 20.9001\nEpoch 758/1000, Train Loss: 0.2187, Validation Loss: 18.8135\nEpoch 759/1000, Train Loss: 0.1877, Validation Loss: 16.5139\nEpoch 760/1000, Train Loss: 0.1793, Validation Loss: 17.0651\nEpoch 761/1000, Train Loss: 0.1237, Validation Loss: 13.3941\nEpoch 762/1000, Train Loss: 0.0881, Validation Loss: 14.4973\nEpoch 763/1000, Train Loss: 0.0701, Validation Loss: 12.2244\nEpoch 764/1000, Train Loss: 0.0535, Validation Loss: 13.6358\nEpoch 765/1000, Train Loss: 0.0754, Validation Loss: 14.6328\nEpoch 766/1000, Train Loss: 0.0808, Validation Loss: 9.5434\nEpoch 767/1000, Train Loss: 0.2452, Validation Loss: 9.7357\nEpoch 768/1000, Train Loss: 0.1793, Validation Loss: 8.0772\nEpoch 769/1000, Train Loss: 0.1460, Validation Loss: 7.8856\nEpoch 770/1000, Train Loss: 0.0989, Validation Loss: 13.5136\nEpoch 771/1000, Train Loss: 0.0932, Validation Loss: 4.4380\nEpoch 772/1000, Train Loss: 0.1042, Validation Loss: 5.9799\nEpoch 773/1000, Train Loss: 0.1416, Validation Loss: 15.1811\nEpoch 774/1000, Train Loss: 0.0880, Validation Loss: 9.4725\nEpoch 775/1000, Train Loss: 0.0958, Validation Loss: 14.6426\nEpoch 776/1000, Train Loss: 0.1001, Validation Loss: 11.5561\nEpoch 777/1000, Train Loss: 0.0605, Validation Loss: 5.2102\nEpoch 778/1000, Train Loss: 0.0495, Validation Loss: 5.6610\nEpoch 779/1000, Train Loss: 0.0529, Validation Loss: 5.6112\nEpoch 780/1000, Train Loss: 0.0408, Validation Loss: 5.6583\nEpoch 781/1000, Train Loss: 0.0428, Validation Loss: 4.9914\nEpoch 782/1000, Train Loss: 0.0384, Validation Loss: 5.2904\nEpoch 783/1000, Train Loss: 0.0436, Validation Loss: 5.2828\nEpoch 784/1000, Train Loss: 0.0613, Validation Loss: 7.0405\nEpoch 785/1000, Train Loss: 0.0867, Validation Loss: 4.6141\nEpoch 786/1000, Train Loss: 0.2176, Validation Loss: 13.2208\nEpoch 787/1000, Train Loss: 0.2539, Validation Loss: 7.7177\nEpoch 788/1000, Train Loss: 0.3762, Validation Loss: 26.7795\nEpoch 789/1000, Train Loss: 0.6035, Validation Loss: 22.3624\nEpoch 790/1000, Train Loss: 0.4466, Validation Loss: 24.8797\nEpoch 791/1000, Train Loss: 0.3655, Validation Loss: 16.5827\nEpoch 792/1000, Train Loss: 0.2008, Validation Loss: 19.6822\nEpoch 793/1000, Train Loss: 0.1318, Validation Loss: 19.1018\nEpoch 794/1000, Train Loss: 0.0859, Validation Loss: 19.4579\nEpoch 795/1000, Train Loss: 0.0732, Validation Loss: 18.5694\nEpoch 796/1000, Train Loss: 0.0883, Validation Loss: 18.2734\nEpoch 797/1000, Train Loss: 0.0713, Validation Loss: 20.2459\nEpoch 798/1000, Train Loss: 0.0582, Validation Loss: 16.5661\nEpoch 799/1000, Train Loss: 0.0686, Validation Loss: 16.2783\nEpoch 800/1000, Train Loss: 0.1275, Validation Loss: 11.9104\nEpoch 801/1000, Train Loss: 0.0875, Validation Loss: 11.7582\nEpoch 802/1000, Train Loss: 0.0748, Validation Loss: 11.9718\nEpoch 803/1000, Train Loss: 0.0610, Validation Loss: 11.6469\nEpoch 804/1000, Train Loss: 0.0765, Validation Loss: 10.4830\nEpoch 805/1000, Train Loss: 0.1073, Validation Loss: 14.7357\nEpoch 806/1000, Train Loss: 0.1461, Validation Loss: 11.4782\nEpoch 807/1000, Train Loss: 0.0665, Validation Loss: 12.2672\nEpoch 808/1000, Train Loss: 0.0733, Validation Loss: 9.6246\nEpoch 809/1000, Train Loss: 0.0667, Validation Loss: 11.6516\nEpoch 810/1000, Train Loss: 0.0723, Validation Loss: 11.1144\nEpoch 811/1000, Train Loss: 0.0536, Validation Loss: 10.6788\nEpoch 812/1000, Train Loss: 0.0485, Validation Loss: 9.4095\nEpoch 813/1000, Train Loss: 0.0416, Validation Loss: 10.2828\nEpoch 814/1000, Train Loss: 0.0386, Validation Loss: 9.9611\nEpoch 815/1000, Train Loss: 0.0532, Validation Loss: 9.7954\nEpoch 816/1000, Train Loss: 0.0775, Validation Loss: 6.2116\nEpoch 817/1000, Train Loss: 0.0595, Validation Loss: 8.2869\nEpoch 818/1000, Train Loss: 0.0657, Validation Loss: 8.1795\nEpoch 819/1000, Train Loss: 0.0593, Validation Loss: 7.8678\nEpoch 820/1000, Train Loss: 0.0515, Validation Loss: 8.9133\nEpoch 821/1000, Train Loss: 0.0413, Validation Loss: 8.4081\nEpoch 822/1000, Train Loss: 0.0851, Validation Loss: 7.8367\nEpoch 823/1000, Train Loss: 0.2771, Validation Loss: 10.5209\nEpoch 824/1000, Train Loss: 0.3675, Validation Loss: 19.6301\nEpoch 825/1000, Train Loss: 0.4576, Validation Loss: 17.0319\nEpoch 826/1000, Train Loss: 0.4535, Validation Loss: 7.7559\nEpoch 827/1000, Train Loss: 0.3070, Validation Loss: 13.4644\nEpoch 828/1000, Train Loss: 0.1310, Validation Loss: 12.1974\nEpoch 829/1000, Train Loss: 0.1214, Validation Loss: 6.8979\nEpoch 830/1000, Train Loss: 0.0681, Validation Loss: 9.2862\nEpoch 831/1000, Train Loss: 0.0569, Validation Loss: 8.8040\nEpoch 832/1000, Train Loss: 0.1324, Validation Loss: 9.9840\nEpoch 833/1000, Train Loss: 0.1125, Validation Loss: 6.8555\nEpoch 834/1000, Train Loss: 0.1155, Validation Loss: 4.9041\nEpoch 835/1000, Train Loss: 0.0981, Validation Loss: 9.1917\nEpoch 836/1000, Train Loss: 0.0592, Validation Loss: 8.0235\nEpoch 837/1000, Train Loss: 0.0701, Validation Loss: 8.6237\nEpoch 838/1000, Train Loss: 0.0511, Validation Loss: 7.8444\nEpoch 839/1000, Train Loss: 0.0449, Validation Loss: 7.5293\nEpoch 840/1000, Train Loss: 0.0388, Validation Loss: 7.0263\nEpoch 841/1000, Train Loss: 0.0396, Validation Loss: 8.0689\nEpoch 842/1000, Train Loss: 0.0503, Validation Loss: 8.6217\nEpoch 843/1000, Train Loss: 0.0385, Validation Loss: 6.6666\nEpoch 844/1000, Train Loss: 0.0447, Validation Loss: 6.7537\nEpoch 845/1000, Train Loss: 0.0485, Validation Loss: 7.1025\nEpoch 846/1000, Train Loss: 0.0548, Validation Loss: 7.5536\nEpoch 847/1000, Train Loss: 0.0478, Validation Loss: 8.2168\nEpoch 848/1000, Train Loss: 0.1195, Validation Loss: 3.9316\nEpoch 849/1000, Train Loss: 0.3314, Validation Loss: 10.6456\nEpoch 850/1000, Train Loss: 0.3403, Validation Loss: 4.3284\nEpoch 851/1000, Train Loss: 0.4001, Validation Loss: 5.4789\nEpoch 852/1000, Train Loss: 0.4645, Validation Loss: 5.0949\nEpoch 853/1000, Train Loss: 0.3280, Validation Loss: 3.6265\nEpoch 854/1000, Train Loss: 0.1335, Validation Loss: 3.8885\nEpoch 855/1000, Train Loss: 0.1050, Validation Loss: 4.1136\nEpoch 856/1000, Train Loss: 0.0747, Validation Loss: 4.1744\nEpoch 857/1000, Train Loss: 0.0591, Validation Loss: 4.2210\nEpoch 858/1000, Train Loss: 0.0534, Validation Loss: 4.0170\nEpoch 859/1000, Train Loss: 0.0557, Validation Loss: 3.9349\nEpoch 860/1000, Train Loss: 0.0581, Validation Loss: 3.9171\nEpoch 861/1000, Train Loss: 0.0414, Validation Loss: 3.7048\nEpoch 862/1000, Train Loss: 0.0401, Validation Loss: 4.2079\nEpoch 863/1000, Train Loss: 0.0370, Validation Loss: 4.1032\nEpoch 864/1000, Train Loss: 0.0399, Validation Loss: 4.1341\nEpoch 865/1000, Train Loss: 0.0429, Validation Loss: 3.9222\nEpoch 866/1000, Train Loss: 0.0378, Validation Loss: 3.6925\nEpoch 867/1000, Train Loss: 0.0417, Validation Loss: 3.6122\nEpoch 868/1000, Train Loss: 0.0571, Validation Loss: 3.9285\nEpoch 869/1000, Train Loss: 0.0893, Validation Loss: 3.8292\nEpoch 870/1000, Train Loss: 0.0551, Validation Loss: 4.0490\nEpoch 871/1000, Train Loss: 0.1757, Validation Loss: 4.9750\nEpoch 872/1000, Train Loss: 0.1942, Validation Loss: 3.6360\nEpoch 873/1000, Train Loss: 0.2390, Validation Loss: 3.5590\nEpoch 874/1000, Train Loss: 0.2931, Validation Loss: 3.7484\nEpoch 875/1000, Train Loss: 0.1400, Validation Loss: 3.1157\nEpoch 876/1000, Train Loss: 0.1599, Validation Loss: 3.3532\nEpoch 877/1000, Train Loss: 0.0967, Validation Loss: 3.3803\nEpoch 878/1000, Train Loss: 0.1000, Validation Loss: 3.1431\nEpoch 879/1000, Train Loss: 0.0665, Validation Loss: 3.0005\nEpoch 880/1000, Train Loss: 0.0909, Validation Loss: 3.0230\nEpoch 881/1000, Train Loss: 0.1143, Validation Loss: 2.8538\nEpoch 882/1000, Train Loss: 0.1042, Validation Loss: 3.2572\nEpoch 883/1000, Train Loss: 0.0818, Validation Loss: 3.4973\nEpoch 884/1000, Train Loss: 0.0839, Validation Loss: 3.2448\nEpoch 885/1000, Train Loss: 0.0811, Validation Loss: 2.9797\nEpoch 886/1000, Train Loss: 0.0862, Validation Loss: 2.8761\nEpoch 887/1000, Train Loss: 0.0591, Validation Loss: 3.0431\nEpoch 888/1000, Train Loss: 0.0440, Validation Loss: 3.0531\nEpoch 889/1000, Train Loss: 0.0455, Validation Loss: 3.0259\nEpoch 890/1000, Train Loss: 0.0466, Validation Loss: 2.9830\nEpoch 891/1000, Train Loss: 0.0579, Validation Loss: 2.8996\nEpoch 892/1000, Train Loss: 0.0655, Validation Loss: 2.7364\nEpoch 893/1000, Train Loss: 0.1335, Validation Loss: 3.0909\nEpoch 894/1000, Train Loss: 0.2410, Validation Loss: 3.2291\nEpoch 895/1000, Train Loss: 0.3912, Validation Loss: 4.7843\nEpoch 896/1000, Train Loss: 0.6246, Validation Loss: 7.8974\nEpoch 897/1000, Train Loss: 0.6645, Validation Loss: 10.5431\nEpoch 898/1000, Train Loss: 0.2093, Validation Loss: 15.0351\nEpoch 899/1000, Train Loss: 0.1118, Validation Loss: 12.9687\nEpoch 900/1000, Train Loss: 0.0984, Validation Loss: 11.7884\nEpoch 901/1000, Train Loss: 0.0970, Validation Loss: 11.6712\nEpoch 902/1000, Train Loss: 0.1133, Validation Loss: 8.5778\nEpoch 903/1000, Train Loss: 0.0654, Validation Loss: 7.2543\nEpoch 904/1000, Train Loss: 0.0691, Validation Loss: 5.6421\nEpoch 905/1000, Train Loss: 0.0619, Validation Loss: 6.0424\nEpoch 906/1000, Train Loss: 0.0479, Validation Loss: 6.3887\nEpoch 907/1000, Train Loss: 0.0443, Validation Loss: 6.8685\nEpoch 908/1000, Train Loss: 0.0570, Validation Loss: 6.0731\nEpoch 909/1000, Train Loss: 0.0595, Validation Loss: 6.4272\nEpoch 910/1000, Train Loss: 0.0812, Validation Loss: 6.1884\nEpoch 911/1000, Train Loss: 0.0689, Validation Loss: 7.5238\nEpoch 912/1000, Train Loss: 0.0594, Validation Loss: 6.3177\nEpoch 913/1000, Train Loss: 0.0474, Validation Loss: 5.8219\nEpoch 914/1000, Train Loss: 0.0422, Validation Loss: 6.2598\nEpoch 915/1000, Train Loss: 0.0444, Validation Loss: 6.4397\nEpoch 916/1000, Train Loss: 0.0416, Validation Loss: 6.0853\nEpoch 917/1000, Train Loss: 0.0382, Validation Loss: 5.7423\nEpoch 918/1000, Train Loss: 0.0515, Validation Loss: 5.4747\nEpoch 919/1000, Train Loss: 0.0454, Validation Loss: 5.7177\nEpoch 920/1000, Train Loss: 0.0428, Validation Loss: 6.4610\nEpoch 921/1000, Train Loss: 0.0352, Validation Loss: 6.2201\nEpoch 922/1000, Train Loss: 0.0370, Validation Loss: 6.8067\nEpoch 923/1000, Train Loss: 0.1397, Validation Loss: 7.1760\nEpoch 924/1000, Train Loss: 0.4808, Validation Loss: 8.8474\nEpoch 925/1000, Train Loss: 0.2326, Validation Loss: 8.1951\nEpoch 926/1000, Train Loss: 0.2035, Validation Loss: 11.8954\nEpoch 927/1000, Train Loss: 0.1586, Validation Loss: 8.6487\nEpoch 928/1000, Train Loss: 0.0836, Validation Loss: 8.7563\nEpoch 929/1000, Train Loss: 0.0856, Validation Loss: 8.6219\nEpoch 930/1000, Train Loss: 0.0961, Validation Loss: 6.6043\nEpoch 931/1000, Train Loss: 0.0619, Validation Loss: 7.5623\nEpoch 932/1000, Train Loss: 0.0488, Validation Loss: 7.6684\nEpoch 933/1000, Train Loss: 0.0410, Validation Loss: 7.7280\nEpoch 934/1000, Train Loss: 0.0515, Validation Loss: 7.6233\nEpoch 935/1000, Train Loss: 0.0476, Validation Loss: 6.6818\nEpoch 936/1000, Train Loss: 0.0471, Validation Loss: 6.2012\nEpoch 937/1000, Train Loss: 0.0587, Validation Loss: 6.8335\nEpoch 938/1000, Train Loss: 0.0955, Validation Loss: 7.5821\nEpoch 939/1000, Train Loss: 0.2233, Validation Loss: 5.9964\nEpoch 940/1000, Train Loss: 0.0966, Validation Loss: 5.2311\nEpoch 941/1000, Train Loss: 0.0982, Validation Loss: 7.5232\nEpoch 942/1000, Train Loss: 0.1254, Validation Loss: 3.2744\nEpoch 943/1000, Train Loss: 0.2436, Validation Loss: 5.9618\nEpoch 944/1000, Train Loss: 0.3607, Validation Loss: 20.9203\nEpoch 945/1000, Train Loss: 0.8485, Validation Loss: 33.3837\nEpoch 946/1000, Train Loss: 1.1255, Validation Loss: 27.9637\nEpoch 947/1000, Train Loss: 0.3461, Validation Loss: 20.5209\nEpoch 948/1000, Train Loss: 0.2050, Validation Loss: 29.6966\nEpoch 949/1000, Train Loss: 0.1920, Validation Loss: 29.5125\nEpoch 950/1000, Train Loss: 0.1070, Validation Loss: 28.0255\nEpoch 951/1000, Train Loss: 0.1017, Validation Loss: 28.5588\nEpoch 952/1000, Train Loss: 0.0596, Validation Loss: 28.7786\nEpoch 953/1000, Train Loss: 0.0728, Validation Loss: 27.5218\nEpoch 954/1000, Train Loss: 0.0614, Validation Loss: 27.9697\nEpoch 955/1000, Train Loss: 0.1218, Validation Loss: 27.9141\nEpoch 956/1000, Train Loss: 0.0957, Validation Loss: 24.5359\nEpoch 957/1000, Train Loss: 0.0878, Validation Loss: 26.9687\nEpoch 958/1000, Train Loss: 0.1214, Validation Loss: 27.6089\nEpoch 959/1000, Train Loss: 0.0731, Validation Loss: 27.1583\nEpoch 960/1000, Train Loss: 0.0511, Validation Loss: 26.3764\nEpoch 961/1000, Train Loss: 0.0605, Validation Loss: 25.9588\nEpoch 962/1000, Train Loss: 0.0609, Validation Loss: 25.5027\nEpoch 963/1000, Train Loss: 0.0524, Validation Loss: 26.2742\nEpoch 964/1000, Train Loss: 0.0454, Validation Loss: 24.3118\nEpoch 965/1000, Train Loss: 0.0686, Validation Loss: 25.6124\nEpoch 966/1000, Train Loss: 0.1309, Validation Loss: 24.4427\nEpoch 967/1000, Train Loss: 0.1857, Validation Loss: 22.8494\nEpoch 968/1000, Train Loss: 0.0894, Validation Loss: 22.3449\nEpoch 969/1000, Train Loss: 0.0639, Validation Loss: 22.3169\nEpoch 970/1000, Train Loss: 0.0768, Validation Loss: 19.7800\nEpoch 971/1000, Train Loss: 0.1671, Validation Loss: 24.1096\nEpoch 972/1000, Train Loss: 0.2010, Validation Loss: 23.5223\nEpoch 973/1000, Train Loss: 0.0612, Validation Loss: 21.0525\nEpoch 974/1000, Train Loss: 0.0790, Validation Loss: 23.9824\nEpoch 975/1000, Train Loss: 0.1312, Validation Loss: 14.9983\nEpoch 976/1000, Train Loss: 0.1527, Validation Loss: 25.1743\nEpoch 977/1000, Train Loss: 0.1743, Validation Loss: 11.7760\nEpoch 978/1000, Train Loss: 0.2428, Validation Loss: 10.7046\nEpoch 979/1000, Train Loss: 0.0813, Validation Loss: 14.7253\nEpoch 980/1000, Train Loss: 0.0771, Validation Loss: 16.3719\nEpoch 981/1000, Train Loss: 0.1696, Validation Loss: 10.2972\nEpoch 982/1000, Train Loss: 0.0656, Validation Loss: 8.6800\nEpoch 983/1000, Train Loss: 0.0634, Validation Loss: 9.9563\nEpoch 984/1000, Train Loss: 0.1233, Validation Loss: 14.5866\nEpoch 985/1000, Train Loss: 0.1148, Validation Loss: 7.3309\nEpoch 986/1000, Train Loss: 0.1163, Validation Loss: 6.6590\nEpoch 987/1000, Train Loss: 0.1055, Validation Loss: 6.3531\nEpoch 988/1000, Train Loss: 0.1057, Validation Loss: 6.6547\nEpoch 989/1000, Train Loss: 0.0556, Validation Loss: 5.7634\nEpoch 990/1000, Train Loss: 0.0483, Validation Loss: 5.2920\nEpoch 991/1000, Train Loss: 0.0488, Validation Loss: 4.8892\nEpoch 992/1000, Train Loss: 0.0456, Validation Loss: 4.7167\nEpoch 993/1000, Train Loss: 0.0429, Validation Loss: 4.9443\nEpoch 994/1000, Train Loss: 0.0422, Validation Loss: 4.6928\nEpoch 995/1000, Train Loss: 0.0349, Validation Loss: 4.5471\nEpoch 996/1000, Train Loss: 0.0454, Validation Loss: 4.8191\nEpoch 997/1000, Train Loss: 0.0391, Validation Loss: 4.7520\nEpoch 998/1000, Train Loss: 0.0403, Validation Loss: 4.6039\nEpoch 999/1000, Train Loss: 0.0460, Validation Loss: 4.4576\nEpoch 1000/1000, Train Loss: 0.0663, Validation Loss: 4.5982\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"min(validation_losses)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:57:22.177280Z","iopub.execute_input":"2024-02-10T09:57:22.178316Z","iopub.status.idle":"2024-02-10T09:57:22.183845Z","shell.execute_reply.started":"2024-02-10T09:57:22.178281Z","shell.execute_reply":"2024-02-10T09:57:22.182965Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.7978744902900264"},"metadata":{}}]},{"cell_type":"markdown","source":"# Testing","metadata":{"papermill":{"duration":0.079193,"end_time":"2024-02-09T10:38:32.970419","exception":false,"start_time":"2024-02-09T10:38:32.891226","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # Your code for loading the data (unchanged)\n# input_file = \"/kaggle/input/transformer-instances-with-prototypes/zero_to_fifty/ssl-n-way-k-shot_test.csv\"\n\n# values = []\n# matrix_labels = []\n\n# with open(input_file, \"r\") as f_input:\n#     reader = csv.reader(f_input)\n#     for row in reader:\n#         row_values = []\n#         for i in range(len(row) - 1):\n#             column_value = ast.literal_eval(row[i])\n#             row_values.append(column_value)\n#         values.append(torch.tensor(row_values))\n#         matrix_labels.append(ast.literal_eval(row[-1]))\n        \n# matrix_labels = np.array(matrix_labels)\n# test_values = torch.stack([value.clone().detach() for value in values])\n# test_matrix_labels = matrix_labels","metadata":{"papermill":{"duration":35.437917,"end_time":"2024-02-09T10:39:08.486546","exception":false,"start_time":"2024-02-09T10:38:33.048629","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-09T22:19:56.835894Z","iopub.execute_input":"2024-02-09T22:19:56.836344Z","iopub.status.idle":"2024-02-09T22:20:31.562861Z","shell.execute_reply.started":"2024-02-09T22:19:56.836315Z","shell.execute_reply":"2024-02-09T22:20:31.562021Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(test_values)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T22:21:25.354645Z","iopub.execute_input":"2024-02-09T22:21:25.355504Z","iopub.status.idle":"2024-02-09T22:21:25.362878Z","shell.execute_reply.started":"2024-02-09T22:21:25.355469Z","shell.execute_reply":"2024-02-09T22:21:25.361234Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"500"},"metadata":{}}]},{"cell_type":"code","source":"stfe = STFE(d, d_prime, d_doble_prime)\nstfe.fc = nn.Linear(d, 50)\nstfe.load_state_dict(torch.load('/kaggle/working/model_epoch_53.pt'))\nstfe.to(device)\n\n# test_batch_size = 16\n# test_dataset = SkeletonDataset(test_values, test_matrix_labels)\n# test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n\n# Put the model in evaluation mode\nstfe.eval()\n\n# Initialize the total loss and the number of correct predictions\ntotal_loss = 0.0\ntotal_correct = 0\n\n# No need to track gradients during testing\nwith torch.no_grad():\n    for batch_idx, (data, labels) in enumerate(test_loader):\n        data, labels = data.to(device), labels.to(device)\n        \n        for i in range(len(data)):\n            # forward + backward + optimize\n            outputs = net(data[i], ssl_sorted_prototype_values)\n            loss = criterion(outputs, labels[i])\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 0)  # Get the predicted class\n            \n            # Count the number of correct predictions\n            total_correct += (predicted == labels[i]).sum().item()\n\n# Calculate the average loss and the accuracy over the entire test set\navg_loss = total_loss / len(test_loader.dataset)\naccuracy = total_correct / len(test_loader.dataset)\n\nprint('Test Loss: %.3f' % avg_loss)\nprint('Test Accuracy: %.3f' % accuracy)","metadata":{"papermill":{"duration":0.431162,"end_time":"2024-02-09T10:39:09.006403","exception":false,"start_time":"2024-02-09T10:39:08.575241","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-10T09:58:36.518888Z","iopub.execute_input":"2024-02-10T09:58:36.519231Z","iopub.status.idle":"2024-02-10T09:58:36.673267Z","shell.execute_reply.started":"2024-02-10T09:58:36.519202Z","shell.execute_reply":"2024-02-10T09:58:36.672040Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test Loss: 1.428\nTest Accuracy: 0.757\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.080769,"end_time":"2024-02-09T10:39:09.163599","exception":false,"start_time":"2024-02-09T10:39:09.082830","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}